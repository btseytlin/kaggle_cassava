{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from argparse import Namespace\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassava.utils import *\n",
    "from cassava.transforms import get_test_transforms\n",
    "from cassava.models.model import LeafDoctorModel\n",
    "from cassava.pipelines.train_model.nodes import score_model\n",
    "from cassava.pipelines.train_model.nodes import split_data, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: captum in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (0.3.0)\n",
      "Requirement already satisfied: matplotlib in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from captum) (3.3.3)\n",
      "Requirement already satisfied: torch>=1.2 in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from captum) (1.7.0)\n",
      "Requirement already satisfied: numpy in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from captum) (1.19.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from matplotlib->captum) (1.3.1)\n",
      "Requirement already satisfied: numpy in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from captum) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from matplotlib->captum) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from matplotlib->captum) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from matplotlib->captum) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from matplotlib->captum) (2.4.7)\n",
      "Requirement already satisfied: six in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->captum) (1.15.0)\n",
      "Requirement already satisfied: six in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from cycler>=0.10->matplotlib->captum) (1.15.0)\n",
      "Requirement already satisfied: dataclasses in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from torch>=1.2->captum) (0.6)\n",
      "Requirement already satisfied: numpy in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from captum) (1.19.4)\n",
      "Requirement already satisfied: typing-extensions in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from torch>=1.2->captum) (3.7.4.3)\n",
      "Requirement already satisfied: future in /home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages (from torch>=1.2->captum) (0.18.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.3; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/home/boris/Documents/kaggle cassava/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import GuidedGradCam,  DeepLift, Occlusion, NoiseTunnel, IntegratedGradients\n",
    "from captum.attr import visualization as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:36:55,436 - kedro.io.data_catalog - INFO - Loading data from `parameters` (MemoryDataSet)...\n"
     ]
    }
   ],
   "source": [
    "parameters = context.catalog.load('parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:36:55,475 - kedro.io.data_catalog - INFO - Loading data from `train` (ImageOneFolderDataSet)...\n"
     ]
    }
   ],
   "source": [
    "train = context.catalog.load('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.labels = (train.sources == 'train_2020').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19749, 6583)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(range(len(train)), stratify=train.labels, random_state=42)\n",
    "len(train_idx), len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5349\n",
       "0    1234\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train.labels[test_idx]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = DatasetFromSubset(Subset(train, indices=test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DatasetFromSubset(Subset(train, indices=train_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model to predict which dataset a picture came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = split_data(train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Namespace(**parameters['classifier'])\n",
    "model = LeafDoctorModel(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['classifier']['batch_size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Checkpoint directory data/06_models/classifier/checkpoints exists and is not empty. With save_top_k=1, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:36:55,846 - lightning - INFO - GPU available: True, used: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:36:55,847 - lightning - INFO - TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:36:55,849 - lightning - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:36:55,850 - lightning - INFO - Using native 16bit precision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | trunk | EfficientNet | 4.0 M \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:36:59,104 - lightning - INFO - \n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | trunk | EfficientNet | 4.0 M \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576579a921504b05ad6e6281d3515e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/boris/Documents/kaggle cassava/venv/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:45: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 0: val_acc reached 0.00000 (best 0.00000), saving model to /home/boris/Documents/kaggle cassava/cassava/notebooks/data/06_models/classifier/checkpoints/epoch=0_val_acc=0.0000-v6.ckpt as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:42:49,180 - lightning - INFO - Epoch 0: val_acc reached 0.00000 (best 0.00000), saving model to /home/boris/Documents/kaggle cassava/cassava/notebooks/data/06_models/classifier/checkpoints/epoch=0_val_acc=0.0000-v6.ckpt as top 1\n",
      "\n",
      "2020-12-27 00:42:49,457 - root - INFO - Training finished\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, train, train_indices, val_indices, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-27 00:42:49,827 - root - INFO - Scoring model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2ec777c492417ab985fb72ef345fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=412.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-12-27 00:43:59,538 - root - INFO - Validation scores:\n",
      "{'accuracy': 0.9825307610511924, 'f1_score': 0.9827674876631308}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9825307610511924, 'f1_score': 0.9827674876631308}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model(model, test, list(range(len(test))), parameters)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret this craziness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying guided grad CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "model = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnorm = Unnormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribution(model, image, source, label):\n",
    "    prep_image_batch = image.unsqueeze(0)\n",
    "    prediction = model.predict(prep_image_batch)[0]\n",
    "    \n",
    "    print('True:', source)\n",
    "    print('Pred:', 'train_2020' if prediction else 'train_2019')\n",
    "\n",
    "    n_samples = 10\n",
    "\n",
    "#     attributor = GuidedGradCam(model, model.trunk.blocks[6][0].conv_pwl)\n",
    "#     attributor = NoiseTunnel(attributor)\n",
    "#     attribution = attributor.attribute(prep_image_batch,\n",
    "#                                        target=target,\n",
    "#                                       n_samples=n_samples)\n",
    "\n",
    "\n",
    "    attributor = DeepLift(model)\n",
    "    attributor = NoiseTunnel(attributor)\n",
    "    attribution = attributor.attribute(prep_image_batch,\n",
    "                                       target=target,\n",
    "                                      baselines=0, n_samples=n_samples)\n",
    "\n",
    "\n",
    "\n",
    "    # attributor = Occlusion(model)\n",
    "    # strides = (3, 5, 5) \n",
    "    # sliding_window_shapes=(3,50,50)\n",
    "    # target = int(label)\n",
    "    # baselines = 0\n",
    "\n",
    "    # attribution = attributor.attribute(prep_image_batch,\n",
    "    #                                    target=target,\n",
    "    #                                    sliding_window_shapes=sliding_window_shapes,\n",
    "    #                                    strides=strides,\n",
    "    #                                    baselines=baselines)\n",
    "\n",
    "    attribution = np.transpose(attribution.squeeze().cpu().detach().numpy(), (1,2,0))\n",
    "    return attribution\n",
    "\n",
    "def visualize_attribution(image, attribution):\n",
    "    vis_types = [\"heat_map\", \"blended_heat_map\", \"original_image\"]\n",
    "    vis_signs = [\"all\", \"all\", \"all\"] # \"positive\", \"negative\", or \"all\" to show both\n",
    "    # positive attribution indicates that the presence of the area increases the prediction score\n",
    "    # negative attribution indicates distractor areas whose absence increases the score\n",
    "\n",
    "    _ = viz.visualize_image_attr_multiple(attribution,\n",
    "                                          unnorm(image.clone()).permute((1, 2, 0)).numpy(),\n",
    "                                          vis_types,\n",
    "                                          vis_signs,\n",
    "                                          vis_types,\n",
    "                                          show_colorbar = True,\n",
    "                                          fig_size=(20, 10)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random train image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_2019 = np.argwhere(train.subset.dataset.sources[train.subset.indices] == 'train_2019').flatten()\n",
    "indices_2020 = np.argwhere(train.subset.dataset.sources[train.subset.indices] == 'train_2020').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5bc4dade07bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprep_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_transforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(indices_2019)\n",
    "source = train.subset.dataset.sources[train.subset.indices][idx]\n",
    "\n",
    "image, label = train[idx]\n",
    "prep_image = get_test_transforms()(image=image)['image']\n",
    "target = int(label)\n",
    "\n",
    "attribution = get_attribution(model, prep_image, source, label)\n",
    "\n",
    "visualize_attribution(prep_image, attribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(indices_2020)\n",
    "source = train.subset.dataset.sources[train.subset.indices][idx]\n",
    "\n",
    "image, label = train[idx]\n",
    "prep_image = get_test_transforms()(image=image)['image']\n",
    "target = int(label)\n",
    "\n",
    "attribution = get_attribution(model, prep_image, source, label)\n",
    "\n",
    "visualize_attribution(prep_image, attribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_2019_test = np.argwhere(test.subset.dataset.sources[test.subset.indices] == 'train_2019').flatten()\n",
    "indices_2020_test = np.argwhere(test.subset.dataset.sources[test.subset.indices] == 'train_2020').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(indices_2019_test)\n",
    "source = test.subset.dataset.sources[test.subset.indices][idx]\n",
    "print(source)\n",
    "\n",
    "image, label = test[idx]\n",
    "prep_image = get_test_transforms()(image=image)['image']\n",
    "target = int(label)\n",
    "\n",
    "attribution = get_attribution(model, prep_image, source, label)\n",
    "\n",
    "visualize_attribution(prep_image, attribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(indices_2020_test)\n",
    "source = test.subset.dataset.sources[test.subset.indices][idx]\n",
    "print(source)\n",
    "\n",
    "image, label = test[idx]\n",
    "prep_image = get_test_transforms()(image=image)['image']\n",
    "target = int(label)\n",
    "\n",
    "attribution = get_attribution(model, prep_image, source, label)\n",
    "\n",
    "visualize_attribution(prep_image, attribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
