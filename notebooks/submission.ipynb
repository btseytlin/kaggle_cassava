{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import logging\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from copy import copy\n",
    "from argparse import Namespace\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ls /kaggle/input/timm-pretrained-efficientnet\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/timm-pretrained-efficientnet/efficientnet/efficientnet_b0_ra-3dd342df.pth /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install /kaggle/input/timm-package/timm-0.1.26-py3-none-any.whl\n",
    "!pip install /kaggle/input/lmdb-python-package/lmdb-1.0.0/dist/lmdb-1.0.0.tar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file transforms.py\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "\n",
    "dummy_transforms = A.Compose([\n",
    "    A.ToFloat(max_value=1.0),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "lmdb_transforms = A.Compose([\n",
    "    A.Resize(400, 400),\n",
    "])\n",
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=5, val_shift_limit=5, p=1),\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.RandomResizedCrop(256, 256, scale=(0.3, 0.9)),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transforms():\n",
    "    return A.Compose([\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.Resize(400, 400),\n",
    "        A.CenterCrop(256, 256),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file utils.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "class Unnormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names) == cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten() / np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels, group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        # Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        # if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf) == 2:\n",
    "            # Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1, 1] / sum(cf[:, 1])\n",
    "            recall = cf[1, 1] / sum(cf[1, :])\n",
    "            f1_score = 2 * precision * recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy, precision, recall, f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize == None:\n",
    "        # Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks == False:\n",
    "        # Do not show categories if xyticks is False\n",
    "        categories = False\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def plot_image(img, label=None, ax=None):\n",
    "    img = torch.Tensor(np.array(img))\n",
    "    label_num_to_disease_map = {0: 'Cassava Bacterial Blight (CBB)',\n",
    "                                1: 'Cassava Brown Streak Disease (CBSD)',\n",
    "                                2: 'Cassava Green Mottle (CGM)',\n",
    "                                3: 'Cassava Mosaic Disease (CMD)',\n",
    "                                4: 'Healthy'}\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    ax.imshow(img.permute(2, 1, 0))\n",
    "    ax.axis('off')\n",
    "    if label is not None:\n",
    "\n",
    "        if isinstance(label, int):\n",
    "            label = label_num_to_disease_map.get(label, 0)\n",
    "        ax.set_title(f'{label}')\n",
    "\n",
    "\n",
    "def plot_label_examples(dataset, targets, target_label):\n",
    "    label_indices = np.where(targets == target_label)[0]\n",
    "\n",
    "    sample = np.random.choice(label_indices, 6)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(2, 3),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, idx in zip(grid, sample):\n",
    "        img, label = dataset[idx]\n",
    "        assert label == target_label\n",
    "        plot_image(img, ax=ax)\n",
    "    plt.suptitle(f'Label {target_label}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(image=x)['image']\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, root, image_ids, labels, transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.targets = self.labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = io.imread(os.path.join(self.root, self.image_ids[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/model.py\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from torch import nn\n",
    "import timm\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeafDoctorModel(pl.LightningModule):\n",
    "    def __init__(self, hparams = None):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams or Namespace()\n",
    "\n",
    "        self.trunk = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        probabilities = nn.functional.softmax(self.forward(x), dim=1)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, x):\n",
    "        return torch.max(self.forward(x), 1)[1]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),\n",
    "                                      lr=self.hparams.lr or self.hparams.learning_rate,\n",
    "                                      weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  patience=self.hparams.reduce_lr_on_pleteau_patience,\n",
    "                                                                  verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "            'monitor': 'val_acc',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True),\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/byol.py\n",
    "\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from copy import deepcopy, copy\n",
    "from itertools import chain\n",
    "from typing import Dict, List\n",
    "import pytorch_lightning as pl\n",
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "import random\n",
    "from typing import Callable, Tuple, Union\n",
    "from kornia import augmentation as aug\n",
    "from kornia import filters\n",
    "from kornia.geometry import transform as tf\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "\n",
    "def normalized_mse(x: Tensor, y: Tensor) -> Tensor:\n",
    "    x = f.normalize(x, dim=-1)\n",
    "    y = f.normalize(y, dim=-1)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn: Callable, p: float):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return x if random.random() > self.p else self.fn(x)\n",
    "\n",
    "\n",
    "def default_augmentation(image_size: Tuple[int, int] = (224, 224)) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        tf.Resize(size=image_size),\n",
    "        RandomApply(aug.ColorJitter(0.2, 0.2, 0.2, 0.2), p=0.8),\n",
    "        aug.RandomVerticalFlip(),\n",
    "        aug.RandomHorizontalFlip(),\n",
    "        RandomApply(filters.GaussianBlur2d((3, 3), (1.0, 1.0)), p=0.1),\n",
    "        aug.RandomResizedCrop(size=image_size, scale=(0.3, 0.7)),\n",
    "        aug.Normalize(\n",
    "            mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "            std=torch.tensor([0.229, 0.224, 0.225]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def mlp(dim: int, projection_size: int = 256, hidden_size: int = 4096) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size),\n",
    "    )\n",
    "\n",
    "\n",
    "class EncoderWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        layer: Union[str, int] = -2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.projection_size = projection_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "\n",
    "        self._projector = None\n",
    "        self._projector_dim = None\n",
    "        self._encoded = torch.empty(0)\n",
    "        self._register_hook()\n",
    "\n",
    "    @property\n",
    "    def projector(self):\n",
    "        if self._projector is None:\n",
    "            self._projector = mlp(\n",
    "                self._projector_dim, self.projection_size, self.hidden_size\n",
    "            )\n",
    "        return self._projector\n",
    "\n",
    "    def _hook(self, _, __, output):\n",
    "        output = output.flatten(start_dim=1)\n",
    "        if self._projector_dim is None:\n",
    "            self._projector_dim = output.shape[-1]\n",
    "        self._encoded = self.projector(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        if isinstance(self.layer, str):\n",
    "            layer = dict([*self.model.named_modules()])[self.layer]\n",
    "        else:\n",
    "            layer = list(self.model.children())[self.layer]\n",
    "\n",
    "        layer.register_forward_hook(self._hook)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _ = self.model(x)\n",
    "        return self._encoded\n",
    "\n",
    "\n",
    "class BYOL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        image_size: Tuple[int, int] = (256, 256),\n",
    "        hidden_layer: Union[str, int] = -2,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        augment_fn: Callable = None,\n",
    "        beta: float = 0.99,\n",
    "        hparams = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.augment = default_augmentation(image_size) if augment_fn is None else augment_fn\n",
    "        self.beta = beta\n",
    "        self.encoder = EncoderWrapper(\n",
    "            model, projection_size, hidden_size, layer=hidden_layer\n",
    "        )\n",
    "        self.predictor = nn.Linear(projection_size, projection_size, hidden_size)\n",
    "        self.hparams = hparams or Namespace()\n",
    "        self._target = None\n",
    "\n",
    "        self.encoder(torch.zeros(2, 3, *image_size))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.predictor(self.encoder(x))\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        if self._target is None:\n",
    "            self._target = deepcopy(self.encoder)\n",
    "        return self._target\n",
    "\n",
    "    def update_target(self):\n",
    "        for p, pt in zip(self.encoder.parameters(), self.target.parameters()):\n",
    "            pt.data = self.beta * pt.data + (1 - self.beta) * p.data\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  patience=self.hparams.reduce_lr_on_pleteau_patience,\n",
    "                                                                  verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "            'monitor': 'train_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        with torch.no_grad():\n",
    "            x1, x2 = self.augment(x), self.augment(x)\n",
    "\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        with torch.no_grad():\n",
    "            targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        x1, x2 = self.augment(x), self.augment(x)\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file node_helpers.py\n",
    "\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def score(predictions, labels):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(predictions, labels),\n",
    "        'f1_score': f1_score(predictions, labels, average='weighted'),\n",
    "    }\n",
    "\n",
    "\n",
    "def predict(model, dataset, indices, batch_size=10, num_workers=4, transform=None):\n",
    "    transform = transform or get_test_transforms()\n",
    "    dataset = DatasetFromSubset(\n",
    "        torch.utils.data.Subset(dataset, indices=indices),\n",
    "        transform=transform)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=False,\n",
    "                                         drop_last=False)\n",
    "\n",
    "    predictions = []\n",
    "    probas = []\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "            batch_probas = model.predict_proba(images)\n",
    "            batch_preds = torch.max(batch_probas, 1)[1]\n",
    "            predictions.append(batch_preds)\n",
    "            probas.append(batch_probas)\n",
    "\n",
    "    predictions = torch.hstack(predictions).flatten().tolist()\n",
    "    probas = torch.vstack(probas).tolist()\n",
    "\n",
    "    return predictions, probas\n",
    "\n",
    "\n",
    "def lr_find(trainer, model, train_data_loader, val_data_loader=None, plot=False):\n",
    "    val_dataloaders = [val_data_loader] if val_data_loader else None\n",
    "\n",
    "    lr_finder = trainer.tuner.lr_find(model,\n",
    "                                      train_dataloader=train_data_loader,\n",
    "                                      val_dataloaders=val_dataloaders)\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.title('LR finder results')\n",
    "        lr_finder.plot(suggest=True)\n",
    "        plt.show()\n",
    "\n",
    "    newlr = lr_finder.suggestion()\n",
    "    logging.info('LR finder suggestion: %f', newlr)\n",
    "\n",
    "    return newlr\n",
    "\n",
    "\n",
    "def train_byol(model, hparams, loader):\n",
    "    byol = BYOL(model, image_size=(256, 256), hparams=hparams)\n",
    "    early_stopping = EarlyStopping('train_loss',\n",
    "                                   patience=hparams.early_stop_patience,\n",
    "                                   verbose=True)\n",
    "\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        hparams,\n",
    "        reload_dataloaders_every_epoch=True,\n",
    "        terminate_on_nan=True,\n",
    "        callbacks=[early_stopping],\n",
    "    )\n",
    "\n",
    "    if hparams.auto_lr_find:\n",
    "        new_lr = lr_find(trainer, byol, loader, val_data_loader=loader)\n",
    "        hparams.lr = new_lr\n",
    "        byol.hparams.lr = new_lr\n",
    "\n",
    "    trainer.fit(byol, loader, loader)\n",
    "    return byol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file lmdb_dataset.py\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from PIL import Image\n",
    "import six\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import lmdb\n",
    "from tqdm.auto import tqdm\n",
    "import pyarrow as pa\n",
    "import lz4framed\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "\n",
    "def compress_serialize(thing):\n",
    "    return pa.serialize(thing).to_buffer()\n",
    "\n",
    "\n",
    "def deserialize_decompress(thing):\n",
    "    return pa.deserialize(thing)\n",
    "\n",
    "\n",
    "def raw_reader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        bin_data = f.read()\n",
    "    return bin_data\n",
    "\n",
    "\n",
    "class ImageLMDBDataset(data.Dataset):\n",
    "    def __init__(self, db_path, transform=None, target_transform=None):\n",
    "        self.db_path = str(db_path)\n",
    "        self.env = lmdb.open(self.db_path, subdir=os.path.isdir(db_path),\n",
    "                                     readonly=True, lock=False,\n",
    "                                     readahead=False, meminit=False)\n",
    "        with self.env.begin(write=False) as txn:\n",
    "            self.length = deserialize_decompress(txn.get(b'__len__'))\n",
    "            self.keys = deserialize_decompress(txn.get(b'__keys__'))\n",
    "            self.labels = deserialize_decompress(txn.get(b'labels'))\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        env = self.env\n",
    "        with env.begin(write=False) as txn:\n",
    "            byteflow = txn.get(self.keys[index])\n",
    "\n",
    "        unpacked = deserialize_decompress(byteflow)\n",
    "        image, label = unpacked\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + self.db_path + ')'\n",
    "\n",
    "\n",
    "def dataset_to_lmdb(dataset, out_path, write_frequency=2000, num_workers=8, map_size=1e11):\n",
    "    dataset.loader = raw_reader\n",
    "    data_loader = DataLoader(dataset, num_workers=num_workers, collate_fn=lambda x: x)\n",
    "\n",
    "    lmdb_path = out_path\n",
    "    isdir = os.path.isdir(lmdb_path)\n",
    "\n",
    "    logging.debug(\"Generate LMDB to %s\" % lmdb_path)\n",
    "    db = lmdb.open(lmdb_path, subdir=isdir,\n",
    "                           map_size=map_size, readonly=False,\n",
    "                           meminit=False, map_async=True)\n",
    "\n",
    "    labels = []\n",
    "    logging.debug(len(dataset), len(data_loader))\n",
    "    txn = db.begin(write=True)\n",
    "    for idx, data in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        image, label = data[0]\n",
    "        txn.put(u'{}'.format(idx).encode('ascii'), compress_serialize((image, label)))\n",
    "        if idx % write_frequency == 0:\n",
    "            txn.commit()\n",
    "            txn = db.begin(write=True)\n",
    "        labels.append(int(label))\n",
    "\n",
    "    # finish iterating through dataset\n",
    "    logging.debug('Final commit')\n",
    "    txn.commit()\n",
    "\n",
    "    logging.debug('Writing keys and len')\n",
    "    keys = [u'{}'.format(k).encode('ascii') for k in range(idx + 1)]\n",
    "    with db.begin(write=True) as txn:\n",
    "        txn.put(b'__keys__', compress_serialize(keys))\n",
    "        txn.put(b'__len__', compress_serialize(len(keys)))\n",
    "        txn.put(b'labels', compress_serialize(list(labels)))\n",
    "\n",
    "    logging.debug(\"Flushing database ...\")\n",
    "    db.sync()\n",
    "    db.close()\n",
    "\n",
    "    return ImageLMDBDataset(out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline prepare\n",
    "\n",
    "def prepare_lmdb(train_images_torch, test_images_torch):\n",
    "    train_images_torch.transform = lmdb_transforms\n",
    "    test_images_torch.transform = lmdb_transforms\n",
    "\n",
    "    train_lmdb_path = 'data/03_primary/train.lmdb'\n",
    "    test_lmdb_path = 'data/03_primary/test.lmdb'\n",
    "\n",
    "    if any([os.path.exists(train_lmdb_path),\n",
    "            os.path.exists(test_lmdb_path)]):\n",
    "        raise Exception('LMDB files lready exist, delete manually to overwrite.')\n",
    "\n",
    "    train_images_lmdb = dataset_to_lmdb(train_images_torch, train_lmdb_path)\n",
    "    test_images_lmdb = dataset_to_lmdb(test_images_torch, test_lmdb_path)\n",
    "\n",
    "    return train_images_lmdb, test_images_lmdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline pretrain\n",
    "\n",
    "def pretrain_model(train_images_lmdb, test_images_lmdb, parameters):\n",
    "    train_images_lmdb.transform = dummy_transforms\n",
    "    test_images_lmdb.transform = dummy_transforms\n",
    "    dataset = torch.utils.data.ConcatDataset([train_images_lmdb, test_images_lmdb])\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                        batch_size=parameters['byol']['batch_size'],\n",
    "                                        num_workers=parameters['data_loader_workers'],\n",
    "                                        shuffle=True)\n",
    "\n",
    "    classifier_params = Namespace(**parameters['classifier'])\n",
    "    model = LeafDoctorModel(classifier_params)\n",
    "\n",
    "    hparams = Namespace(**parameters['byol'])\n",
    "    byol = train_byol(model.trunk, hparams, loader)\n",
    "\n",
    "    state_dict = byol.encoder.model.state_dict()\n",
    "    model = LeafDoctorModel(classifier_params)\n",
    "    model.trunk.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline train\n",
    "\n",
    "def split_data(train_labels, parameters):\n",
    "    \"\"\"Splits trainig data into the train and validation set\"\"\"\n",
    "    train_indices, val_indices = train_test_split(range(len(train_labels)),\n",
    "                     stratify=train_labels.label,\n",
    "                     random_state=parameters['seed'],\n",
    "                     test_size=parameters['validation_size'])\n",
    "    return train_indices, val_indices\n",
    "\n",
    "\n",
    "def train_model(pretrained_model, train_images_lmdb, train_indices, val_indices, parameters):\n",
    "    train_transform, val_transform = get_train_transforms(), get_test_transforms()\n",
    "\n",
    "    train_dataset = DatasetFromSubset(torch.utils.data.Subset(train_images_lmdb, indices=train_indices),\n",
    "                                      transform=train_transform)\n",
    "\n",
    "    val_dataset = DatasetFromSubset(torch.utils.data.Subset(train_images_lmdb, indices=val_indices),\n",
    "                                    transform=val_transform)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                    batch_size=parameters['classifier']['batch_size'],\n",
    "                                                    num_workers=parameters['data_loader_workers'],\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                                  num_workers=parameters['data_loader_workers'],\n",
    "                                                  batch_size=parameters['classifier']['batch_size'])\n",
    "\n",
    "    # Callbacks\n",
    "    model_checkpoint = ModelCheckpoint(monitor=\"val_acc\",\n",
    "                                       verbose=True,\n",
    "                                       dirpath=parameters['classifier']['checkpoints_dir'],\n",
    "                                       filename=\"{epoch}_{val_acc:.4f}\",\n",
    "                                       save_top_k=parameters['classifier']['save_top_k_checkpoints'])\n",
    "    early_stopping = EarlyStopping('val_acc',\n",
    "                                   patience=parameters['classifier']['early_stop_patience'],\n",
    "                                   verbose=True,\n",
    "                                   )\n",
    "\n",
    "    hparams = Namespace(**parameters['classifier'])\n",
    "\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        hparams,\n",
    "        reload_dataloaders_every_epoch = True,\n",
    "        terminate_on_nan=True,\n",
    "        callbacks=[model_checkpoint, early_stopping],\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = LeafDoctorModel(hparams)\n",
    "    model.load_state_dict(pretrained_model.state_dict())\n",
    "\n",
    "    # Training\n",
    "    trainer.fit(model, train_data_loader, val_data_loader)\n",
    "    logging.info('Training finished')\n",
    "\n",
    "    # Saving\n",
    "    best_checkpoint = model_checkpoint.best_model_path\n",
    "    model = LeafDoctorModel().load_from_checkpoint(checkpoint_path=best_checkpoint)\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_model(model, train_images_torch, indices, parameters):\n",
    "    logging.info('Scoring model')\n",
    "    if parameters['classifier'].get('limit_val_batches'):\n",
    "        indices = indices[:parameters['classifier']['limit_val_batches']*parameters['classifier']['batch_size']]\n",
    "    labels = train_images_torch.labels[indices]\n",
    "    predictions, probas = predict(model,\n",
    "                          dataset=train_images_torch,\n",
    "                          indices=indices,\n",
    "                          batch_size=parameters['classifier']['batch_size'],\n",
    "                          num_workers=parameters['data_loader_workers'],\n",
    "                          transform=get_test_transforms())\n",
    "\n",
    "    scores = score(predictions, labels)\n",
    "\n",
    "    logging.info(f'Validation scores:\\n{scores}')\n",
    "    return scores, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline predict\n",
    "\n",
    "def predict_submission(model, test_images_lmdb, sample_submission, parameters):\n",
    "    logging.debug('Predicting with model')\n",
    "    test_images_lmdb.transform = get_test_transforms()\n",
    "\n",
    "    predictions, probas = predict(model,\n",
    "                                  dataset=test_images_lmdb,\n",
    "                                  indices=list(range(len(test_images_lmdb))),\n",
    "                                  batch_size=parameters['classifier']['batch_size'],\n",
    "                                  num_workers=parameters['data_loader_workers'],\n",
    "                                  transform=get_test_transforms())\n",
    "\n",
    "    sample_submission.label = predictions\n",
    "\n",
    "    return sample_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline cv\n",
    "\n",
    "def cross_validation(pretrained_model, train_images_lmdb, test_images_lmdb, parameters):\n",
    "    cv_results = {}\n",
    "    score_values = {}\n",
    "\n",
    "    if os.path.exists(parameters['cv_models_dir']):\n",
    "        raise Exception('CV models path already exists, please delete it explicitly to overwrite')\n",
    "    else:\n",
    "        os.makedirs(parameters['cv_models_dir'])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=parameters['cv_splits'], random_state=parameters['seed'])\n",
    "    indices = np.array(list(range(len(train_images_lmdb))))\n",
    "    labels = train_images_lmdb.labels\n",
    "    for fold_num, (train_idx, val_idx) in enumerate(cv.split(indices, labels)):\n",
    "        logging.info('Fitting CV fold %d', fold_num)\n",
    "        model_path = os.path.join(parameters['cv_models_dir'], f'model_fold_{fold_num}.pt')\n",
    "        fold_parameters = copy(parameters)\n",
    "        model = train_model(pretrained_model, train_images_lmdb, train_idx, val_idx, fold_parameters)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        scores, oof_predictions = score_model(model, train_images_lmdb, val_idx, fold_parameters)\n",
    "        cv_results[f'fold_{fold_num}'] = {\n",
    "            'model_path': model_path,\n",
    "            'scores': scores,\n",
    "            'val_indices': val_idx,\n",
    "            'oof_predictions': oof_predictions,\n",
    "        }\n",
    "\n",
    "        for score in scores:\n",
    "            if not score_values.get(score):\n",
    "                score_values[score] = []\n",
    "            score_values[score].append(scores[score])\n",
    "\n",
    "    cv_results['summary'] = {}\n",
    "    for score_name, scores in score_values.items():\n",
    "        cv_results['summary'][f'{score_name}_mean'] = np.mean(scores)\n",
    "        cv_results['summary'][f'{score_name}_std'] = np.std(scores)\n",
    "\n",
    "    logging.info('Cross-validation results %s')\n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"seed\": 42,\n",
    "    \"validation_size\": 0.15,\n",
    "    \"data_loader_workers\": 4,\n",
    "    \"classifier\": {\n",
    "        \"gpus\": -1,\n",
    "        \"batch_size\": 10,\n",
    "        \"max_epochs\": 100,\n",
    "        \"max_steps\": 0,\n",
    "        \"auto_lr_find\": 0,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"early_stop_patience\": 4,\n",
    "        \"reduce_lr_on_pleteau_patience\": 3,\n",
    "        \"save_top_k_checkpoints\": 1,\n",
    "        \"checkpoints_dir\": \"data/06_models/classifier/checkpoints\"\n",
    "    },\n",
    "    \"byol\": {\n",
    "        \"gpus\": -1,\n",
    "        \"batch_size\": 10,\n",
    "        \"max_epochs\": 100,\n",
    "        \"max_steps\": 0,\n",
    "        \"auto_lr_find\": 1,\n",
    "        \"lr\": 0.01,\n",
    "        \"reduce_lr_on_pleteau_patience\": 1,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"limit_train_batches\": 300,\n",
    "        \"limit_val_batches\": 1,\n",
    "        \"accumulate_grad_batches\": 4,\n",
    "        \"early_stop_patience\": 3,\n",
    "        \"from_checkpoint\": 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = '/kaggle/input/cassava-leaf-disease-classification'\n",
    "\n",
    "train_labels = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "sample_submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "label_num_to_disease_map = pd.read_csv(f'{DATA_DIR}/label_num_to_disease_map.json')\n",
    "\n",
    "train_images_torch = CassavaDataset(image_ids=train_labels.image_id.values, labels=train_labels.label.values, root=f'{DATA_DIR}/train_images')\n",
    "test_images_torch = CassavaDataset(image_ids=sample_submission.image_id.values, labels=sample_submission.label.values, root=f'{DATA_DIR}/test_images')\n",
    "\n",
    "pretrained_model_path = '/kaggle/input/byol-pretrained-cassava/pretrained_model_best.pt'\n",
    "pretrained_model = LeafDoctorModel(hparams=Namespace(**parameters['classifier']))\n",
    "pretrained_model.load_state_dict(torch.load(pretrained_model_path))\n",
    "\n",
    "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_lmdb, test_images_lmdb = prepare_lmdb(train_images_torch, test_images_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = split_data(train_labels, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = pretrain_model(train_images_lmdb, test_images_lmdb, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(pretrained_model, train_images_lmdb, train_indices, val_indices, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predict_submission(model, test_images_lmdb, sample_submission, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores, val_predictions = score_model(model, train_images_lmdb, val_indices, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
