{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import logging\n",
    "from skimage.io import imsave\n",
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import imagehash\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from copy import copy\n",
    "import os\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import ConcatDataset, Subset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xf /kaggle/input/cassava-merged/dataset.tar.xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ls /kaggle/input/timm-pretrained-efficientnet\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/timm-pretrained-efficientnet/efficientnet/efficientnet_b0_ra-3dd342df.pth /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install /kaggle/input/timm-package/timm-0.1.26-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file transforms.py\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def data_preapre_transform(image):\n",
    "    \"\"\"Transforms a PIL Image to have aspec ratio 8/6\"\"\"\n",
    "    image = Image.fromarray(np.array(image))\n",
    "    if image.size[0] < image.size[1]:\n",
    "        image = image.rotate(90, expand=True)\n",
    "\n",
    "    # Center crop until 8:6\n",
    "    width, height = image.size   # Get dimensions\n",
    "\n",
    "    if round(width/height, 3) != round(8/6, 3):\n",
    "        new_height = int(height*(width/height * 6/8))\n",
    "        new_width = width\n",
    "\n",
    "        left = (width - new_width)/2\n",
    "        top = (height - new_height)/2\n",
    "        right = (width + new_width)/2\n",
    "        bottom = (height + new_height)/2\n",
    "\n",
    "        image = image.crop((left, top, right, bottom))\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_wrapper(transforms):\n",
    "    def wraps(img):\n",
    "        return transforms(image=np.array(img))['image']\n",
    "    return wraps\n",
    "\n",
    "\n",
    "def get_byol_transforms(width, height):\n",
    "    byol_transforms = A.Compose([\n",
    "        A.Resize(width, height),\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    return get_wrapper(byol_transforms)\n",
    "\n",
    "\n",
    "def get_prepare_transforms(width, height):\n",
    "    prepare_transforms = A.Compose([\n",
    "        A.Resize(width, height),\n",
    "    ])\n",
    "\n",
    "    return get_wrapper(prepare_transforms)\n",
    "\n",
    "\n",
    "def get_train_transforms(width, height):\n",
    "    train_transforms = A.Compose([\n",
    "        A.JpegCompression(quality_lower=95, quality_upper=100, p=0.5),\n",
    "        A.ColorJitter(p=0.5),\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.ShiftScaleRotate(p=0.5),\n",
    "        A.RandomResizedCrop(width, height, scale=(0.1, 0.8)),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    return get_wrapper(train_transforms)\n",
    "\n",
    "\n",
    "def get_test_transforms(width, height):\n",
    "    test_transforms = A.Compose([\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.CenterCrop(width, height),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    return get_wrapper(test_transforms)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file utils.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "class Unnormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names) == cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten() / np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels, group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        # Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        # if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf) == 2:\n",
    "            # Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1, 1] / sum(cf[:, 1])\n",
    "            recall = cf[1, 1] / sum(cf[1, :])\n",
    "            f1_score = 2 * precision * recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy, precision, recall, f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize == None:\n",
    "        # Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks == False:\n",
    "        # Do not show categories if xyticks is False\n",
    "        categories = False\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def plot_image(img, label=None, ax=None):\n",
    "    new_img = torch.Tensor(np.array(img))\n",
    "    label_num_to_disease_map = {0: 'Cassava Bacterial Blight (CBB)',\n",
    "                                1: 'Cassava Brown Streak Disease (CBSD)',\n",
    "                                2: 'Cassava Green Mottle (CGM)',\n",
    "                                3: 'Cassava Mosaic Disease (CMD)',\n",
    "                                4: 'Healthy'}\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    ax.imshow(new_img.permute(2, 1, 0))\n",
    "    ax.axis('off')\n",
    "    if label is not None:\n",
    "\n",
    "        if isinstance(label, int):\n",
    "            label = label_num_to_disease_map.get(label, 0)\n",
    "        ax.set_title(f'{label}')\n",
    "\n",
    "\n",
    "def plot_label_examples(dataset, targets, target_label):\n",
    "    label_indices = np.where(targets == target_label)[0]\n",
    "\n",
    "    sample = np.random.choice(label_indices, 6)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(2, 3),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, idx in zip(grid, sample):\n",
    "        img, label = dataset[idx]\n",
    "        assert label == target_label\n",
    "        plot_image(img, ax=ax)\n",
    "    plt.suptitle(f'Label {target_label}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None, target_transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getattr__(self, item):\n",
    "        if item in self.__dict__:\n",
    "            return getattr(self, item)\n",
    "\n",
    "        return getattr(self.subset.dataset, item)[self.subset.indices]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "        return x, y\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self.subset.dataset.labels[self.subset.indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, root, image_ids, labels, sources=None, transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.targets = self.labels\n",
    "        self.sources = sources\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = io.imread(os.path.join(self.root, self.image_ids[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/model.py\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from torch import nn\n",
    "import timm\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "def dfs_freeze(model, unfreeze=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = unfreeze\n",
    "\n",
    "    for name, child in model.named_children():\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = unfreeze\n",
    "        dfs_freeze(child, unfreeze=unfreeze)\n",
    "\n",
    "\n",
    "class LeafDoctorModel(pl.LightningModule):\n",
    "    def __init__(self, hparams = None, only_train_layers=None):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams or Namespace()\n",
    "        self.only_train_layers = only_train_layers\n",
    "\n",
    "        self.trunk = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n",
    "\n",
    "        # Freeze layers that dont require grad\n",
    "        if only_train_layers:\n",
    "            dfs_freeze(self.trunk)\n",
    "\n",
    "            for layer_name_or_getter in only_train_layers:\n",
    "                if isinstance(layer_name_or_getter, str):\n",
    "                    layer = getattr(self.trunk, layer_name_or_getter)\n",
    "\n",
    "                else:\n",
    "                    layer = layer_name_or_getter(self.trunk)\n",
    "                dfs_freeze(layer, unfreeze=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        probabilities = nn.functional.softmax(self.forward(x), dim=1)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, x):\n",
    "        return torch.max(self.forward(x), 1)[1]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        trainable_params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "        optimizer = torch.optim.Adam(trainable_params,\n",
    "                                      lr=self.hparams.lr or self.hparams.learning_rate,\n",
    "                                      weight_decay=self.hparams.weight_decay)\n",
    "\n",
    "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                           max_lr=self.hparams.lr,\n",
    "                                                           epochs=self.hparams.max_epochs,\n",
    "                                                           steps_per_epoch=int(23712/self.hparams.batch_size))\n",
    "        return (\n",
    "            [optimizer],\n",
    "            [\n",
    "                {\n",
    "                    'scheduler': lr_scheduler,\n",
    "                    'interval': 'step',\n",
    "                    'frequency': 1,\n",
    "                    'reduce_on_plateau': False,\n",
    "                    'monitor': 'val_loss',\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = bi_tempered_logistic_loss(y_hat, y,\n",
    "                                         self.hparams.bitempered_t1,\n",
    "                                         self.hparams.bitempered_t2,\n",
    "                                         label_smoothing=self.hparams.label_smoothing)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False, prog_bar=False, logger=True)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True),\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/byol.py\n",
    "\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "from typing import Dict, List\n",
    "import pytorch_lightning as pl\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "import random\n",
    "from typing import Callable, Tuple, Union\n",
    "from kornia import augmentation as aug\n",
    "from kornia import filters\n",
    "from kornia.geometry import transform as tf\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "def normalized_mse(x: Tensor, y: Tensor) -> Tensor:\n",
    "    x = f.normalize(x, dim=-1)\n",
    "    y = f.normalize(y, dim=-1)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn: Callable, p: float):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return x if random.random() > self.p else self.fn(x)\n",
    "\n",
    "\n",
    "def default_aug(image_size: Tuple[int, int] = (360, 360)) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        aug.ColorJitter(contrast=0.1, brightness=0.1, saturation=0.1, p=0.8),\n",
    "        aug.RandomVerticalFlip(),\n",
    "        aug.RandomHorizontalFlip(),\n",
    "        RandomApply(filters.GaussianBlur2d((3, 3), (0.5, 0.5)), p=0.1),\n",
    "        aug.RandomResizedCrop(size=image_size, scale=(0.5, 1)),\n",
    "        aug.Normalize(\n",
    "            mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "            std=torch.tensor([0.229, 0.224, 0.225]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def mlp(dim: int, projection_size: int = 256, hidden_size: int = 4096) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size),\n",
    "    )\n",
    "\n",
    "\n",
    "class EncoderWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        layer: Union[str, int] = -2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.projection_size = projection_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "\n",
    "        self._projector = None\n",
    "        self._projector_dim = None\n",
    "        self._encoded = torch.empty(0)\n",
    "        self._register_hook()\n",
    "\n",
    "    @property\n",
    "    def projector(self):\n",
    "        if self._projector is None:\n",
    "            self._projector = mlp(\n",
    "                self._projector_dim, self.projection_size, self.hidden_size\n",
    "            )\n",
    "        return self._projector\n",
    "\n",
    "    def _hook(self, _, __, output):\n",
    "        output = output.flatten(start_dim=1)\n",
    "        if self._projector_dim is None:\n",
    "            self._projector_dim = output.shape[-1]\n",
    "        self._encoded = self.projector(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        if isinstance(self.layer, str):\n",
    "            layer = dict([*self.model.named_modules()])[self.layer]\n",
    "        else:\n",
    "            layer = list(self.model.children())[self.layer]\n",
    "\n",
    "        layer.register_forward_hook(self._hook)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _ = self.model(x)\n",
    "        return self._encoded\n",
    "\n",
    "\n",
    "class BYOL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        image_size: Tuple[int, int] = (360, 360),\n",
    "        hidden_layer: Union[str, int] = -2,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        augment_fn: Callable = None,\n",
    "        beta: float = 0.99,\n",
    "        hparams = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._augment = default_aug(image_size) if augment_fn is None else augment_fn\n",
    "        self.beta = beta\n",
    "        self.encoder = EncoderWrapper(\n",
    "            model, projection_size, hidden_size, layer=hidden_layer\n",
    "        )\n",
    "        self.predictor = nn.Linear(projection_size, projection_size, hidden_size)\n",
    "        self.hparams = hparams or Namespace()\n",
    "        self._target = None\n",
    "\n",
    "        self.encoder(torch.zeros(2, 3, *image_size, device=self.device))\n",
    "\n",
    "    def augment(self, batch):\n",
    "        if self.hparams.precision == 16:\n",
    "            return self._augment(batch.double()).to(torch.float16)\n",
    "        return self._augment(batch)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.predictor(self.encoder(x))\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        if self._target is None:\n",
    "            self._target = deepcopy(self.encoder)\n",
    "        return self._target\n",
    "\n",
    "    def update_target(self):\n",
    "        for p, pt in zip(self.encoder.parameters(), self.target.parameters()):\n",
    "            pt.data = self.beta * pt.data + (1 - self.beta) * p.data\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        trainable_params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "        optimizer = optim.AdamW(trainable_params, lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                                           max_lr=self.hparams.lr,\n",
    "                                                           epochs=self.hparams.max_epochs,\n",
    "                                                           steps_per_epoch=self.hparams.limit_train_batches)\n",
    "        return (\n",
    "            [optimizer],\n",
    "            [\n",
    "                {\n",
    "                    'scheduler': lr_scheduler,\n",
    "                    'interval': 'step',\n",
    "                    'frequency': 1,\n",
    "                    'reduce_on_plateau': False,\n",
    "                    'monitor': 'val_loss',\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        with torch.no_grad():\n",
    "            x1, x2 = self.augment(x), self.augment(x)\n",
    "\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        with torch.no_grad():\n",
    "            targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        self.log(\"train_loss\", float(loss.detach()), on_step=True)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        x1, x2 = self.augment(x), self.augment(x)\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", float(val_loss.detach()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file node_helpers.py\n",
    "\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def score(predictions, labels):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(predictions, labels),\n",
    "        'f1_score': f1_score(predictions, labels, average='weighted'),\n",
    "    }\n",
    "\n",
    "\n",
    "def predict(model, dataset, indices, batch_size=10, num_workers=4, transform=None):\n",
    "    dataset = DatasetFromSubset(\n",
    "        Subset(dataset, indices=indices),\n",
    "        transform=transform)\n",
    "\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "    predictions = []\n",
    "    probas = []\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "            batch_probas = model.predict_proba(images)\n",
    "            batch_preds = torch.max(batch_probas, 1)[1]\n",
    "            predictions.append(batch_preds)\n",
    "            probas.append(batch_probas)\n",
    "\n",
    "    predictions = torch.hstack(predictions).flatten().tolist()\n",
    "    probas = torch.vstack(probas).tolist()\n",
    "\n",
    "    return predictions, probas\n",
    "\n",
    "\n",
    "def lr_find(trainer, model, train_data_loader, val_data_loader=None, plot=False):\n",
    "    val_dataloaders = [val_data_loader] if val_data_loader else None\n",
    "\n",
    "    lr_finder = trainer.tuner.lr_find(model,\n",
    "                                      train_dataloader=train_data_loader,\n",
    "                                      val_dataloaders=val_dataloaders)\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.title('LR finder results')\n",
    "        lr_finder.plot(suggest=True)\n",
    "        plt.show()\n",
    "\n",
    "    newlr = lr_finder.suggestion()\n",
    "    logging.info('LR finder suggestion: %f', newlr)\n",
    "\n",
    "    return newlr\n",
    "\n",
    "\n",
    "def train_classifier(model, train_loader, hparams, only_train_layers=None, log_training=True, logger_name='classifier'):\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=logger_name) if log_training else None\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        hparams,\n",
    "        reload_dataloaders_every_epoch=True,\n",
    "        terminate_on_nan=True,\n",
    "        precision=hparams.precision,\n",
    "        amp_level=hparams.amp_level,\n",
    "        callbacks=[lr_monitor],\n",
    "        log_every_n_steps=hparams.log_every_n_steps,\n",
    "        flush_logs_every_n_steps=hparams.flush_logs_every_n_steps,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    new_model = LeafDoctorModel(hparams, only_train_layers=only_train_layers)\n",
    "    new_model.load_state_dict(model.state_dict())\n",
    "    model = new_model\n",
    "\n",
    "    # Training\n",
    "    trainer.fit(model, train_loader)\n",
    "    logging.info('Training finished')\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_byol(model, loader, byol_parameters, log_training=True, logger_name='byol'):\n",
    "    only_train_layers = [\n",
    "        lambda trunk: trunk.blocks[-1],\n",
    "        lambda trunk: trunk.conv_head,\n",
    "        lambda trunk: trunk.bn2,\n",
    "        lambda trunk: trunk.global_pool,\n",
    "        lambda trunk: trunk.act2,\n",
    "        lambda trunk: trunk.classifier,\n",
    "    ]\n",
    "    new_model = LeafDoctorModel(only_train_layers=only_train_layers)\n",
    "    new_model.load_state_dict(model.state_dict())\n",
    "    model = new_model\n",
    "\n",
    "    hparams = Namespace(**byol_parameters)\n",
    "\n",
    "    logger = TensorBoardLogger(\"lightning_logs\", name=logger_name) if log_training else None\n",
    "    byol = BYOL(model.trunk, hparams=hparams)\n",
    "    early_stopping = EarlyStopping('train_loss',\n",
    "                                   mode='min',\n",
    "                                   patience=hparams.early_stop_patience,\n",
    "                                   verbose=True)\n",
    "    lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        hparams,\n",
    "        reload_dataloaders_every_epoch=True,\n",
    "        terminate_on_nan=True,\n",
    "        callbacks=[early_stopping, lr_monitor],\n",
    "        precision=hparams.precision,\n",
    "        amp_level=hparams.amp_level,\n",
    "        log_every_n_steps=hparams.log_every_n_steps,\n",
    "        flush_logs_every_n_steps=hparams.flush_logs_every_n_steps,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    if hparams.auto_lr_find:\n",
    "        new_lr = lr_find(trainer, byol, loader)\n",
    "        hparams.lr = new_lr\n",
    "        byol.hparams.lr = new_lr\n",
    "\n",
    "    trainer.fit(byol, loader, loader)\n",
    "\n",
    "    pretrained_model = LeafDoctorModel(None)\n",
    "    pretrained_model.trunk.load_state_dict(byol.encoder.model.state_dict())\n",
    "    return pretrained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file bitempered_loss.py\n",
    "\n",
    "# https://github.com/fhopfmueller/bi-tempered-loss-pytorch/blob/master/bi_tempered_loss_pytorch.py\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def log_t(u, t):\n",
    "    \"\"\"Compute log_t for `u'.\"\"\"\n",
    "    if t == 1.0:\n",
    "        return u.log()\n",
    "    else:\n",
    "        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "\n",
    "def exp_t(u, t):\n",
    "    \"\"\"Compute exp_t for `u'.\"\"\"\n",
    "    if t == 1:\n",
    "        return u.exp()\n",
    "    else:\n",
    "        return (1.0 + (1.0 - t) * u).relu().pow(1.0 / (1.0 - t))\n",
    "\n",
    "\n",
    "def compute_normalization_fixed_point(activations, t, num_iters):\n",
    "    \"\"\"Returns the normalization value for each example (t > 1.0).\n",
    "\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same shape as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations_step_0 = activations - mu\n",
    "\n",
    "    normalized_activations = normalized_activations_step_0\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = torch.sum(\n",
    "            exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "        normalized_activations = normalized_activations_step_0 * \\\n",
    "                                 logt_partition.pow(1.0 - t)\n",
    "\n",
    "    logt_partition = torch.sum(\n",
    "        exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "    return normalization_constants\n",
    "\n",
    "\n",
    "def compute_normalization_binary_search(activations, t, num_iters):\n",
    "    \"\"\"Returns the normalization value for each example (t < 1.0).\n",
    "\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (< 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations = activations - mu\n",
    "\n",
    "    effective_dim = \\\n",
    "        torch.sum(\n",
    "            (normalized_activations > -1.0 / (1.0 - t)).to(torch.int32),\n",
    "            dim=-1, keepdim=True).to(activations.dtype)\n",
    "\n",
    "    shape_partition = activations.shape[:-1] + (1,)\n",
    "    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n",
    "    upper = -log_t(1.0 / effective_dim, t) * torch.ones_like(lower)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = (upper + lower) / 2.0\n",
    "        sum_probs = torch.sum(\n",
    "            exp_t(normalized_activations - logt_partition, t),\n",
    "            dim=-1, keepdim=True)\n",
    "        update = (sum_probs < 1.0).to(activations.dtype)\n",
    "        lower = torch.reshape(\n",
    "            lower * update + (1.0 - update) * logt_partition,\n",
    "            shape_partition)\n",
    "        upper = torch.reshape(\n",
    "            upper * (1.0 - update) + update * logt_partition,\n",
    "            shape_partition)\n",
    "\n",
    "    logt_partition = (upper + lower) / 2.0\n",
    "    return logt_partition + mu\n",
    "\n",
    "\n",
    "class ComputeNormalization(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, activations, t, num_iters):\n",
    "        if t < 1.0:\n",
    "            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n",
    "        else:\n",
    "            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n",
    "\n",
    "        ctx.save_for_backward(activations, normalization_constants)\n",
    "        ctx.t = t\n",
    "        return normalization_constants\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        activations, normalization_constants = ctx.saved_tensors\n",
    "        t = ctx.t\n",
    "        normalized_activations = activations - normalization_constants\n",
    "        probabilities = exp_t(normalized_activations, t)\n",
    "        escorts = probabilities.pow(t)\n",
    "        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n",
    "        grad_input = escorts * grad_output\n",
    "\n",
    "        return grad_input, None, None\n",
    "\n",
    "\n",
    "def compute_normalization(activations, t, num_iters=5):\n",
    "    \"\"\"Returns the normalization value for each example.\n",
    "    Backward pass is implemented.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    return ComputeNormalization.apply(activations, t, num_iters)\n",
    "\n",
    "\n",
    "def tempered_sigmoid(activations, t, num_iters=5):\n",
    "    \"\"\"Tempered sigmoid function.\n",
    "\n",
    "    Args:\n",
    "      activations: Activations for the positive class for binary classification.\n",
    "      t: Temperature tensor > 0.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "                                        torch.zeros_like(activations)],\n",
    "                                       dim=-1)\n",
    "    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n",
    "    return internal_probabilities[..., 0]\n",
    "\n",
    "\n",
    "def tempered_softmax(activations, t, num_iters=5):\n",
    "    \"\"\"Tempered softmax function.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature > 1.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    if t == 1.0:\n",
    "        return activations.softmax(dim=-1)\n",
    "\n",
    "    normalization_constants = compute_normalization(activations, t, num_iters)\n",
    "    return exp_t(activations - normalization_constants, t)\n",
    "\n",
    "\n",
    "def bi_tempered_binary_logistic_loss(activations,\n",
    "                                     labels,\n",
    "                                     t1,\n",
    "                                     t2,\n",
    "                                     label_smoothing=0.0,\n",
    "                                     num_iters=5,\n",
    "                                     reduction='mean'):\n",
    "    \"\"\"Bi-Tempered binary logistic loss.\n",
    "\n",
    "    Args:\n",
    "      activations: A tensor containing activations for class 1.\n",
    "      labels: A tensor with shape as activations, containing probabilities for class 1\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing\n",
    "      num_iters: Number of iterations to run the method.\n",
    "\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "                                        torch.zeros_like(activations)],\n",
    "                                       dim=-1)\n",
    "    internal_labels = torch.stack([labels.to(activations.dtype),\n",
    "                                   1.0 - labels.to(activations.dtype)],\n",
    "                                  dim=-1)\n",
    "    return bi_tempered_logistic_loss(internal_activations,\n",
    "                                     internal_labels,\n",
    "                                     t1,\n",
    "                                     t2,\n",
    "                                     label_smoothing=label_smoothing,\n",
    "                                     num_iters=num_iters,\n",
    "                                     reduction=reduction)\n",
    "\n",
    "\n",
    "def bi_tempered_logistic_loss(activations,\n",
    "                              labels,\n",
    "                              t1,\n",
    "                              t2,\n",
    "                              label_smoothing=0.0,\n",
    "                              num_iters=5,\n",
    "                              reduction='mean'):\n",
    "    \"\"\"Bi-Tempered Logistic Loss.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      labels: A tensor with shape and dtype as activations (onehot),\n",
    "        or a long tensor of one dimension less than activations (pytorch standard)\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n",
    "      num_iters: Number of iterations to run the method. Default 5.\n",
    "      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n",
    "        ``'none'``: No reduction is applied, return shape is shape of\n",
    "        activations without the last dimension.\n",
    "        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n",
    "        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(labels.shape) < len(activations.shape):  # not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = (1 - label_smoothing * num_classes / (num_classes - 1)) \\\n",
    "                        * labels_onehot + \\\n",
    "                        label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "                  - labels_onehot * log_t(probabilities, t1) \\\n",
    "                  - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "                  + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim=-1)  # sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline prepare\n",
    "\n",
    "def obtain_image_hashes(train_images_torch_2020, train_images_torch_2019, test_images_torch_2019, extra_images_torch_2019):\n",
    "    # Adapted from https://www.kaggle.com/zzy990106/duplicate-images-in-two-competitions\n",
    "    datasets = {\n",
    "        'train_2020': train_images_torch_2020,\n",
    "        'train_2019': train_images_torch_2019,\n",
    "        'test_2019': test_images_torch_2019,\n",
    "        'extra_2019': extra_images_torch_2019,\n",
    "    }\n",
    "\n",
    "    image_ids = []\n",
    "    hashes = []\n",
    "\n",
    "    logging.info('Obtaining hashes')\n",
    "\n",
    "    for dname, ds in tqdm(datasets.items()):\n",
    "        loader = DataLoader(ds, num_workers=6, batch_size=None, pin_memory=True)\n",
    "        for ix, (image, label) in tqdm(enumerate(loader), total=len(loader), desc=dname):\n",
    "            if dname in ['test_2019', 'extra_2019']:\n",
    "                label = None\n",
    "\n",
    "            if label is not None:\n",
    "                label = int(label)\n",
    "            img_id = (dname, ix, label)\n",
    "            pil_img = Image.fromarray(np.array(image))\n",
    "            hash = get_img_hash(pil_img)\n",
    "            image_ids.append(img_id)\n",
    "            hashes.append(hash)\n",
    "\n",
    "    image_ids_df = pd.DataFrame(image_ids, columns=['ds', 'ix', 'label'])\n",
    "    hashes_df = pd.DataFrame(np.array(hashes).astype(int))\n",
    "\n",
    "    return image_ids_df, hashes_df\n",
    "\n",
    "\n",
    "def find_duplicates(image_ids, image_hashes):\n",
    "    # Adapted from https://www.kaggle.com/zzy990106/duplicate-images-in-two-competitions\n",
    "    image_ids = image_ids.values\n",
    "    hashes = image_hashes.values\n",
    "\n",
    "    hashes_all = np.array(hashes)\n",
    "    hashes_all = torch.Tensor(hashes_all.astype(int))\n",
    "\n",
    "    logging.info('Computing similarities and finding duplicates')\n",
    "    sim_threshold = int(0.9 * hashes_all.shape[1])\n",
    "    duplicates = []\n",
    "    for i in tqdm(range(hashes_all.shape[0])):\n",
    "        sim = ((hashes_all[i] == hashes_all).sum(dim=1).numpy() > sim_threshold).astype(int)\n",
    "        dupes = np.nonzero(sim)[0]\n",
    "        if len(dupes) > 1:\n",
    "            for dup in dupes:\n",
    "                if dup != i:\n",
    "                    duplicates.append(tuple(sorted([i, dup])))\n",
    "\n",
    "    duplicates = list(set(duplicates))\n",
    "\n",
    "    out_rows = []\n",
    "    for duplicate_pair in duplicates:\n",
    "        image_id1 = image_ids[duplicate_pair[0]]\n",
    "        image_id2 = image_ids[duplicate_pair[1]]\n",
    "        out_rows.append(\n",
    "            # ds1 | id1 | label1 | ds2 | id2 | label2\n",
    "            (*image_id1, *image_id2)\n",
    "        )\n",
    "\n",
    "    out_rows = pd.DataFrame(list(set(out_rows)), columns=['ds1', 'id1', 'label1', 'ds2', 'id2', 'label2'])\n",
    "    return out_rows\n",
    "\n",
    "\n",
    "def prepare_dataset(train_images_torch_2020, train_images_torch_2019, test_images_torch_2019, extra_images_torch_2019, duplicates):\n",
    "    blacklist = dict(duplicates[['ds2', 'id2']].groupby('ds2').agg({'id2': list})['id2'])\n",
    "\n",
    "    train_images_torch_2020.transform = data_preapre_transform\n",
    "    train_images_torch_2019.transform = data_preapre_transform\n",
    "    test_images_torch_2019.transform = data_preapre_transform\n",
    "    extra_images_torch_2019.transform = data_preapre_transform\n",
    "\n",
    "    prepare_transforms = get_prepare_transforms(512, 512)\n",
    "    train_dataset_2020 = DatasetFromSubset(\n",
    "        Subset(train_images_torch_2020, indices=[i for i in range(len(train_images_torch_2020)) if i not in blacklist['train_2020']]),\n",
    "        transform=prepare_transforms)\n",
    "\n",
    "    train_dataset_2019 = DatasetFromSubset(\n",
    "        Subset(train_images_torch_2019,\n",
    "               indices=[i for i in range(len(train_images_torch_2019)) if i not in blacklist['train_2019']]),\n",
    "        transform=prepare_transforms)\n",
    "\n",
    "    test_dataset_2019 = DatasetFromSubset(\n",
    "        Subset(test_images_torch_2019,\n",
    "               indices=[i for i in range(len(test_images_torch_2019)) if i not in blacklist['test_2019']]),\n",
    "        transform=prepare_transforms, target_transform=lambda y: -1)\n",
    "\n",
    "    extra_images_torch_2019 = DatasetFromSubset(\n",
    "        Subset(extra_images_torch_2019,\n",
    "               indices=[i for i in range(len(extra_images_torch_2019)) if i not in blacklist['extra_2019']]),\n",
    "        transform=prepare_transforms, target_transform=lambda y: -1)\n",
    "\n",
    "    train_dataset = ConcatDataset([train_dataset_2020, train_dataset_2019])\n",
    "    train_sources = ['train_2020']*len(train_dataset_2020) + ['train_2019']*len(train_dataset_2019)\n",
    "\n",
    "    unlabelled_dataset = ConcatDataset([test_dataset_2019, extra_images_torch_2019])\n",
    "    unlabelled_sources = ['test_2019'] * len(test_dataset_2019) + ['extra_2019'] * len(extra_images_torch_2019)\n",
    "\n",
    "    train_path = 'data/03_primary/train'\n",
    "    train_csv_path = 'data/03_primary/train.csv'\n",
    "    unlabelled_path = 'data/03_primary/unlabelled'\n",
    "    unlabelled_csv_path = 'data/03_primary/unlabelled.csv'\n",
    "\n",
    "    if any([os.path.exists(train_path),\n",
    "            os.path.exists(unlabelled_path)]):\n",
    "        raise Exception('Dataset folders already exist, delete manually to overwrite.')\n",
    "\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(unlabelled_path, exist_ok=True)\n",
    "\n",
    "    def make_image_folder(dataset, sources, path, csv_path):\n",
    "        loader = DataLoader(dataset, batch_size=None, num_workers=6, collate_fn=lambda x: x)\n",
    "        rows = []\n",
    "        for ix, (image, label) in enumerate(tqdm(loader)):\n",
    "            image_id = f'{ix}.jpg'\n",
    "            source = sources[ix]\n",
    "            img_path = os.path.join(path, image_id)\n",
    "            imsave(img_path, image)\n",
    "            rows.append((image_id, label, source))\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=['image_id', 'label', 'source'])\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        return df\n",
    "\n",
    "    train_df = make_image_folder(train_dataset, train_sources, train_path, train_csv_path)\n",
    "    unlabelled_df = make_image_folder(unlabelled_dataset, unlabelled_sources, unlabelled_path, unlabelled_csv_path)\n",
    "    return CassavaDataset(train_path, train_df.image_id, train_df.label), CassavaDataset(unlabelled_path, unlabelled_df.image_id, unlabelled_df.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline pretrain\n",
    "\n",
    "def pretrain_model(train, unlabelled, parameters):\n",
    "    byol_transforms = get_byol_transforms(parameters['byol']['width'], parameters['byol']['height'])\n",
    "    train_dataset = DatasetFromSubset(\n",
    "        Subset(train, indices=list(range(len(train)))),\n",
    "        transform=byol_transforms)\n",
    "    unlabelled_dataset = DatasetFromSubset(\n",
    "        Subset(unlabelled, indices=list(range(len(unlabelled)))),\n",
    "        transform=byol_transforms)\n",
    "    dataset = ConcatDataset([train_dataset, unlabelled_dataset])\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=parameters['byol']['batch_size'],\n",
    "                        num_workers=parameters['data_loader_workers'],\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True)\n",
    "\n",
    "    byol_params = parameters['byol']\n",
    "    model = LeafDoctorModel()\n",
    "    pretrained_model = train_byol(model, loader,\n",
    "                                  byol_parameters=byol_params,\n",
    "                                  log_training=parameters['log_training'],\n",
    "                                  logger_name='byol_train')\n",
    "    return pretrained_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline train\n",
    "\n",
    "def train_model(pretrained_model, train, parameters):\n",
    "    train_transform = get_train_transforms(parameters['classifier']['train_width'], parameters['classifier']['train_height'])\n",
    "\n",
    "    train_dataset = DatasetFromSubset(Subset(train, indices=list(range(len(train)))),\n",
    "                                      transform=train_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                                batch_size=parameters['classifier']['batch_size'],\n",
    "                                num_workers=parameters['data_loader_workers'],\n",
    "                                shuffle=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "    hparams = Namespace(**parameters['classifier'])\n",
    "\n",
    "    # Train\n",
    "    logging.info('Training model')\n",
    "    model = train_classifier(pretrained_model, train_loader, hparams=hparams)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline predict\n",
    "\n",
    "def predict_submission(cv_results, train, test_images_torch_2020, sample_submission, parameters):\n",
    "    logging.debug('Predicting on test with model')\n",
    "\n",
    "    fold_model_names = [cv_results[fold]['model_path'] for fold in cv_results if fold != 'summary']\n",
    "\n",
    "    all_probas = []\n",
    "    for model_path in fold_model_names:\n",
    "        model = LeafDoctorModel(hparams = Namespace(**parameters['classifier']))\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        finetune_cv_model(model, train, test_images_torch_2020, parameters)\n",
    "\n",
    "        predictions, probas = predict(model,\n",
    "                                  dataset=test_images_torch_2020,\n",
    "                                  indices=list(range(len(test_images_torch_2020))),\n",
    "                                  batch_size=parameters['eval']['batch_size'],\n",
    "                                  num_workers=parameters['data_loader_workers'],\n",
    "                                  transform=get_test_transforms(parameters['classifier']['test_width'], parameters['classifier']['test_height']))\n",
    "\n",
    "        all_probas.append(probas)\n",
    "\n",
    "    aggregated_probas = np.mean(all_probas, axis=0).reshape(-1, 5)\n",
    "    pred_labels = np.argmax(aggregated_probas, 1)\n",
    "    sample_submission.label = pred_labels\n",
    "    return sample_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline cv\n",
    "\n",
    "def obtain_cv_splits(train, parameters):\n",
    "    labels = train.labels\n",
    "    sources = train.sources\n",
    "    indices_2020 = np.argwhere(sources == 'train_2020').flatten()\n",
    "    indices_2019 = np.argwhere(sources == 'train_2019').flatten()\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=parameters['cv_splits'], random_state=parameters['seed'])\n",
    "\n",
    "    splits = []\n",
    "    # Preserve same class distribution in both train and test\n",
    "    # Only put 2020 data in test\n",
    "    splits_2019 = list(cv.split(indices_2019, labels[indices_2020][:len(indices_2019)]))\n",
    "    splits_2020 = list(cv.split(indices_2020, labels[indices_2020]))\n",
    "    for (train_2019_idx, test_2019_idx), (train_2020_idx, test_2020_idx) in zip(splits_2019, splits_2020):\n",
    "        train_idx = np.concatenate([indices_2019[train_2019_idx], indices_2020[train_2020_idx]])\n",
    "        test_idx = indices_2020[test_2020_idx]\n",
    "        splits.append((train_idx, test_idx))\n",
    "    return splits\n",
    "\n",
    "\n",
    "def cross_validation(train, unlabelled, cv_splits, parameters):\n",
    "    cv_results = {\n",
    "        'summary': {},\n",
    "    }\n",
    "    score_values = {\n",
    "        'test': defaultdict(list),\n",
    "        'val': defaultdict(list),\n",
    "    }\n",
    "\n",
    "    if os.path.exists(parameters['cv_models_dir']) and len(os.listdir(parameters['cv_models_dir'])) > 0:\n",
    "        raise Exception('CV models path already exists, please delete it explicitly to overwrite')\n",
    "    else:\n",
    "        os.makedirs(parameters['cv_models_dir'], exist_ok=True)\n",
    "\n",
    "    for fold_num, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        logging.info('Fitting CV fold %d', fold_num)\n",
    "        model_path = os.path.join(parameters['cv_models_dir'], f'model_fold_{fold_num}.pt')\n",
    "        fold_parameters = copy(parameters)\n",
    "\n",
    "        fold_train_dataset = DatasetFromSubset(Subset(train, indices=train_idx))\n",
    "        fold_test_dataset = DatasetFromSubset(Subset(train, indices=test_idx))\n",
    "\n",
    "        # Split\n",
    "        logging.info('Pretraining on train+unlabelled')\n",
    "        pretrained_model = pretrain_model(fold_train_dataset, unlabelled, fold_parameters)\n",
    "\n",
    "        logging.info('Training on train')\n",
    "        model = train_model(pretrained_model, fold_train_dataset, fold_parameters)\n",
    "\n",
    "        logging.info('Finetuning with BYOL')\n",
    "        model = finetune_byol_test(model, fold_train_dataset, fold_test_dataset, fold_parameters)\n",
    "\n",
    "        logging.info('Finetuning for test resolution')\n",
    "        model = finetune_classifier_resolution(model, fold_train_dataset, fold_parameters)\n",
    "\n",
    "        logging.info('Done training CV fold')\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Score on test\n",
    "        test_scores, test_predictions = score_model(model, fold_test_dataset, list(range(len(fold_test_dataset))), fold_parameters)\n",
    "\n",
    "        cv_results[f'fold_{fold_num}'] = {\n",
    "            'model_path': model_path,\n",
    "            'test_indices': test_idx,\n",
    "            'test_scores': test_scores,\n",
    "            'test_predictions': test_predictions,\n",
    "        }\n",
    "\n",
    "        for score in test_scores:\n",
    "            score_values['test'][score].append(test_scores[score])\n",
    "\n",
    "    for score_set in score_values:\n",
    "        for score_name, scores in score_values[score_set].items():\n",
    "            cv_results['summary'][f'{score_set}_{score_name}_mean'] = np.mean(scores)\n",
    "            cv_results['summary'][f'{score_set}_{score_name}_std'] = np.std(scores)\n",
    "\n",
    "    logging.info('Cross-validation results %s', cv_results['summary'])\n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline finetune\n",
    "\n",
    "def finetune_byol_test(pretrained_model, train, test_images_torch_2020, parameters):\n",
    "    byol_transforms = get_byol_transforms(parameters['byol']['width'], parameters['byol']['height'])\n",
    "\n",
    "    train_2020_indices = np.argwhere(train.sources == 'train_2020').flatten()\n",
    "    train_2020 = DatasetFromSubset(Subset(train, indices=train_2020_indices))\n",
    "    dataset = torch.utils.data.ConcatDataset([train_2020, test_images_torch_2020])\n",
    "    dataset = DatasetFromSubset(\n",
    "        torch.utils.data.Subset(dataset, indices=list(range(len(dataset)))),\n",
    "        transform = byol_transforms)\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=parameters['byol']['batch_size'],\n",
    "                                         num_workers=parameters['data_loader_workers'],\n",
    "                                         shuffle=True,\n",
    "                                         pin_memory=True)\n",
    "\n",
    "    byol_params = dict(parameters['byol'])\n",
    "    byol_test_overrides = dict(parameters['byol']['on_test'])\n",
    "    byol_params.update(byol_test_overrides)\n",
    "\n",
    "    finetuned_model = train_byol(pretrained_model, loader,\n",
    "                                  byol_parameters=byol_params,\n",
    "                                  log_training=parameters['log_training'],\n",
    "                                  logger_name='byol_test')\n",
    "    return finetuned_model\n",
    "\n",
    "\n",
    "def finetune_classifier_resolution(model, train, parameters):\n",
    "    logging.info('Finetuning model for test image size')\n",
    "\n",
    "    train_2020_indices = np.argwhere(train.sources == 'train_2020').flatten()\n",
    "    train_2020 = DatasetFromSubset(Subset(train, indices=train_2020_indices))\n",
    "\n",
    "    train_transform = get_train_transforms(parameters['classifier']['test_width'],\n",
    "                                           parameters['classifier']['test_height'])\n",
    "    train_dataset = DatasetFromSubset(Subset(train_2020, indices=list(range(len(train_2020)))),\n",
    "                                      transform=train_transform)\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=parameters['classifier']['batch_size'],\n",
    "                              num_workers=parameters['data_loader_workers'],\n",
    "                              shuffle=True,\n",
    "                              pin_memory=True)\n",
    "\n",
    "    hparams = dict(parameters['classifier'])\n",
    "    hparams.update(dict(parameters['classifier']['finetune']))\n",
    "    hparams = Namespace(**hparams)\n",
    "\n",
    "    only_train_layers = [\n",
    "        lambda trunk: trunk.blocks[-1],\n",
    "        lambda trunk: trunk.conv_head,\n",
    "        lambda trunk: trunk.bn2,\n",
    "        lambda trunk: trunk.global_pool,\n",
    "        lambda trunk: trunk.act2,\n",
    "        lambda trunk: trunk.classifier,\n",
    "    ]\n",
    "    model = train_classifier(model, train_loader,\n",
    "                             hparams=hparams,\n",
    "                             only_train_layers=only_train_layers,\n",
    "                             log_training=parameters['log_training'],\n",
    "                             logger_name='classifier_finetune')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"seed\": 42,\n",
    "    \"cv_splits\": 4,\n",
    "    \"cv_models_dir\": \"data/06_models/cv_folds\",\n",
    "    \"validation_size\": 0.15,\n",
    "    \"data_loader_workers\": 6,\n",
    "    \"log_training\": 1,\n",
    "    \"classifier\": {\n",
    "        \"train_height\": 320,\n",
    "        \"train_width\": 320,\n",
    "        \"test_height\": 400,\n",
    "        \"test_width\": 400,\n",
    "        \"gpus\": -1,\n",
    "        \"batch_size\": 20,\n",
    "        \"accumulate_grad_batches\": 1,\n",
    "        \"max_epochs\": 20,\n",
    "        \"max_steps\": 0,\n",
    "        \"auto_lr_find\": 0,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"bitempered_t1\": 0.8,\n",
    "        \"bitempered_t2\": 1.2,\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"amp_level\": \"O2\",\n",
    "        \"precision\": 16,\n",
    "        \"log_every_n_steps\": 10,\n",
    "        \"flush_logs_every_n_steps\": 100,\n",
    "        \"finetune\": {\n",
    "            \"max_epochs\": 10,\n",
    "            \"lr\": 0.0001\n",
    "        }\n",
    "    },\n",
    "    \"byol\": {\n",
    "        \"width\": 400,\n",
    "        \"height\": 400,\n",
    "        \"gpus\": -1,\n",
    "        \"batch_size\": 12,\n",
    "        \"accumulate_grad_batches\": 1,\n",
    "        \"max_epochs\": 10,\n",
    "        \"max_steps\": 0,\n",
    "        \"auto_lr_find\": 0,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"limit_train_batches\": 100,\n",
    "        \"limit_val_batches\": 1,\n",
    "        \"early_stop_patience\": 3,\n",
    "        \"amp_level\": \"02\",\n",
    "        \"precision\": 16,\n",
    "        \"log_every_n_steps\": 10,\n",
    "        \"flush_logs_every_n_steps\": 100,\n",
    "        \"on_test\": {\n",
    "            \"lr\": 0.0001,\n",
    "            \"auto_lr_find\": 0,\n",
    "            \"max_epochs\": 10,\n",
    "            \"early_stop_patience\": 1\n",
    "        }\n",
    "    },\n",
    "    \"eval\": {\n",
    "        \"batch_size\": 16\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = '/kaggle/input/cassava-leaf-disease-classification'\n",
    "TRAIN_DATA_DIR = '.'\n",
    "MODELS_DIR = '/kaggle/input/cassava-models'\n",
    "\n",
    "sample_submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "\n",
    "train_csv = pd.read_csv(f'{TRAIN_DATA_DIR}/train.csv')\n",
    "train = CassavaDataset(image_ids=train_csv.image_id.values,\n",
    "                        labels=train_csv.label.values, \n",
    "                        sources=train_csv.source.values, \n",
    "                        root=f'{TRAIN_DATA_DIR}/train')\n",
    "\n",
    "\n",
    "test_images_torch_2020 = CassavaDataset(image_ids=sample_submission.image_id.values, labels=sample_submission.label.values, root=f'{DATA_DIR}/test_images')\n",
    "\n",
    "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "\n",
    "cv_results = {\n",
    "    'fold_0': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_0.pt')\n",
    "    },\n",
    "    'fold_1': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_1.pt')\n",
    "    },\n",
    "    'fold_2': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_2.pt')\n",
    "    },\n",
    "    'fold_3': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_3.pt')\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predict_submission(cv_results, train, test_images_torch_2020, sample_submission, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
