{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import logging\n",
    "import numpy as np\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file transforms.py\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.Resize(256, 256),\n",
    "        A.RandomResizedCrop(227, 227, scale=(0.4, 1), ratio=(0.75, 1.33)),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transforms():\n",
    "    return A.Compose([\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.Resize(256, 256),\n",
    "        A.CenterCrop(227, 227),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file utils.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "class Unnormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def plot_image(img, label=None, ax=None):\n",
    "    img = torch.Tensor(np.array(img))\n",
    "    label_num_to_disease_map = {0: 'Cassava Bacterial Blight (CBB)',\n",
    "                                1: 'Cassava Brown Streak Disease (CBSD)',\n",
    "                                2: 'Cassava Green Mottle (CGM)',\n",
    "                                3: 'Cassava Mosaic Disease (CMD)',\n",
    "                                4: 'Healthy'}\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    ax.imshow(img.permute(2, 1, 0))\n",
    "    ax.axis('off')\n",
    "    if label is not None:\n",
    "\n",
    "        if isinstance(label, int):\n",
    "            label = label_num_to_disease_map.get(label, 0)\n",
    "        ax.set_title(f'{label}')\n",
    "\n",
    "\n",
    "def plot_label_examples(dataset, targets, target_label):\n",
    "    label_indices = np.where(targets == target_label)[0]\n",
    "\n",
    "    sample = np.random.choice(label_indices, 6)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(2, 3),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, idx in zip(grid, sample):\n",
    "        img, label = dataset[idx]\n",
    "        assert label == target_label\n",
    "        plot_image(img, ax=ax)\n",
    "    plt.suptitle(f'Label {target_label}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(image=x)['image']\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, root, image_ids, labels, transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.targets = self.labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = io.imread(os.path.join(self.root, self.image_ids[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/resnet50.py\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class ResnetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        trunk = models.resnet18(pretrained=True)\n",
    "        head = nn.Linear(trunk.fc.in_features, 5)\n",
    "\n",
    "        self.trunk = trunk\n",
    "        self.trunk.fc = head\n",
    "        self.head = self.trunk.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk.forward(x)\n",
    "\n",
    "    def predict(self, x):\n",
    "        logits = self.forward(x)\n",
    "        probabilities = nn.functional.softmax(logits, dim=1)\n",
    "        return probabilities\n",
    "\n",
    "    def predict_label(self, x):\n",
    "        return torch.max(self.predict(x), 1)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline train\n",
    "\n",
    "def split_data(train_labels, parameters):\n",
    "    \"\"\"Splits trainig data into the train and validation set\"\"\"\n",
    "    train_indices, val_indices = train_test_split(range(len(train_labels)),\n",
    "                     stratify=train_labels.label,\n",
    "                     random_state=parameters['seed'],\n",
    "                     test_size=parameters['validation_size'])\n",
    "    return train_indices, val_indices\n",
    "\n",
    "\n",
    "def train_model(train_images_torch, train_indices, val_indices, parameters):\n",
    "    train_transform, val_transform = get_train_transforms(), get_test_transforms()\n",
    "\n",
    "    train_dataset = DatasetFromSubset(torch.utils.data.Subset(train_images_torch, indices=train_indices),\n",
    "                                      transform=train_transform)\n",
    "\n",
    "    val_dataset = DatasetFromSubset(torch.utils.data.Subset(train_images_torch, indices=val_indices),\n",
    "                                    transform=val_transform)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                    batch_size=parameters['batch_size'],\n",
    "                                                    num_workers=parameters['data_loader_workers'],\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_dataset, num_workers=parameters['data_loader_workers'], batch_size=parameters['batch_size'])\n",
    "\n",
    "    model = ResnetModel()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=parameters['learning_rate'], weight_decay=parameters['weight_decay'])\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=parameters['reduce_lr_on_pleteau_patience'], verbose=True)\n",
    "\n",
    "    model = model.to(parameters['device'])\n",
    "    criterion = criterion.to(parameters['device'])\n",
    "\n",
    "    early_stop_patience = parameters['early_stop_patience']\n",
    "    early_stop_counter = 0\n",
    "    previous_min_val_loss = None\n",
    "\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "\n",
    "    train_epoch_losses = []\n",
    "    validation_epoch_losses = []\n",
    "\n",
    "    logging.info('Training model')\n",
    "    epoch_pbar = tqdm(range(parameters['train_epochs']))\n",
    "    for epoch in epoch_pbar:\n",
    "        model.train()\n",
    "\n",
    "        logging.debug(\"Epoch %d\", epoch)\n",
    "        epoch_train_losses = []\n",
    "        epoch_val_losses = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_data_loader), total=len(train_data_loader))\n",
    "        for i, batch in pbar:\n",
    "            if i > parameters['batches_per_epoch']:\n",
    "                break\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(parameters['device'])\n",
    "            labels = labels.to(parameters['device'])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model.forward(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_losses.append(loss.item())\n",
    "            pbar.set_postfix({'batch loss': round(loss.item(), 4)})\n",
    "\n",
    "        model.eval()\n",
    "        for i, batch in tqdm(enumerate(val_data_loader), total=len(val_data_loader)):\n",
    "            if i > parameters['batches_per_epoch']:\n",
    "                break\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = batch\n",
    "                inputs = inputs.to(parameters['device'])\n",
    "                labels = labels.to(parameters['device'])\n",
    "\n",
    "                outputs = model.forward(inputs)\n",
    "                val_loss = criterion(outputs, labels)\n",
    "\n",
    "                epoch_val_losses.append(val_loss.item())\n",
    "\n",
    "        epoch_mean_val_loss = sum(epoch_val_losses)/len(epoch_val_losses)\n",
    "        epoch_mean_train_loss = sum(epoch_train_losses)/len(epoch_train_losses)\n",
    "        if previous_min_val_loss is None:\n",
    "            previous_min_val_loss = epoch_mean_val_loss\n",
    "        elif epoch_mean_val_loss < previous_min_val_loss:\n",
    "            previous_min_val_loss = epoch_mean_val_loss\n",
    "            early_stop_counter = 0\n",
    "            logging.debug('New minimum val loss %f, early stopping reset', previous_min_val_loss)\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            logging.debug('Early stop counter now %d', early_stop_counter)\n",
    "\n",
    "        lr_scheduler.step(sum(epoch_train_losses))\n",
    "\n",
    "        train_epoch_losses.append(epoch_mean_train_loss)\n",
    "        validation_epoch_losses.append(epoch_mean_val_loss)\n",
    "        logging.info(\"Epoch mean train loss %f\", epoch_mean_train_loss)\n",
    "        logging.info(\"Epoch mean val loss %f\", epoch_mean_val_loss)\n",
    "\n",
    "        epoch_pbar.set_postfix({\n",
    "            'train loss': epoch_mean_train_loss,\n",
    "            'val loss': epoch_mean_val_loss,\n",
    "        })\n",
    "\n",
    "        train_losses += epoch_train_losses\n",
    "        validation_losses += epoch_val_losses\n",
    "\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            logging.info('Early stopped.')\n",
    "            break\n",
    "\n",
    "    logging.info('Training finished')\n",
    "\n",
    "    metrics = {\n",
    "        'train_losses': train_losses,\n",
    "        'validation_losses': validation_losses,\n",
    "        'train_epoch_losses': train_epoch_losses,\n",
    "        'validation_epoch_losses': validation_epoch_losses,\n",
    "        'last_epoch': epoch,\n",
    "    }\n",
    "\n",
    "    return model, metrics\n",
    "\n",
    "\n",
    "def score_model(model, train_images_torch, indices, parameters):\n",
    "    logging.debug('Scoring model')\n",
    "\n",
    "    device = parameters['device']\n",
    "\n",
    "    dataset = DatasetFromSubset(torch.utils.data.Subset(train_images_torch, indices=indices),\n",
    "                      transform=get_test_transforms())\n",
    "    loader = torch.utils.data.DataLoader(dataset, num_workers=parameters['data_loader_workers'], batch_size=parameters['batch_size'])\n",
    "\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    for images, labels in tqdm(loader):\n",
    "        batch_preds = model.predict_label(images.to(device))\n",
    "        predictions += batch_preds.tolist()\n",
    "        true_labels += labels.tolist()\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy_score(predictions, true_labels),\n",
    "        'confusion_matrix': confusion_matrix(predictions, true_labels),\n",
    "        'f1_score': f1_score(predictions, true_labels, average='weighted'),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline predict\n",
    "\n",
    "def predict(model, test_images_torch, sample_submission, parameters):\n",
    "    logging.debug('Predicting with model')\n",
    "\n",
    "    device = parameters['device']\n",
    "\n",
    "    test_images_torch.transform = get_test_transforms()\n",
    "    loader = torch.utils.data.DataLoader(test_images_torch, batch_size=parameters['batch_size'])\n",
    "\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    for images, labels in tqdm(loader):\n",
    "        batch_preds = model.predict_label(images.to(device))\n",
    "        predictions += batch_preds.tolist()\n",
    "\n",
    "    sample_submission.label = predictions\n",
    "\n",
    "    return sample_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"device\": \"cuda\",\n",
    "    \"seed\": 42,\n",
    "    \"validation_size\": 0.2,\n",
    "    \"data_loader_workers\": 6,\n",
    "    \"batch_size\": 10,\n",
    "    \"train_epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"early_stop_patience\": 4,\n",
    "    \"reduce_lr_on_pleteau_patience\": 3,\n",
    "    \"batches_per_epoch\": 999999999\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../input/resnet18/resnet18.pth /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DATA_DIR = '../data/01_raw'\n",
    "\n",
    "train_labels = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "sample_submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "label_num_to_disease_map = pd.read_csv(f'{DATA_DIR}/label_num_to_disease_map.json')\n",
    "\n",
    "train_images_torch = CassavaDataset(image_ids=train_labels.image_id.values, labels=train_labels.label.values, root=f'{DATA_DIR}/train_images')\n",
    "test_images_torch = CassavaDataset(image_ids=sample_submission.image_id.values, labels=sample_submission.label.values, root=f'{DATA_DIR}/test_images')\n",
    "\n",
    "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, val_indices = split_data(train_labels, parameters)\n",
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, train_metrics = train_model(train_images_torch, train_indices, val_indices, parameters)\n",
    "model, train_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scores = score_model(model, train_images_torch, val_indices, parameters)\n",
    "val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predict(model, test_images_torch, sample_submission, parameters)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
