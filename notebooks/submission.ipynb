{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning import Trainer\n",
    "from copy import copy\n",
    "import seaborn as sns\n",
    "from torch import nn\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "efficientnet_path='/kaggle/input/efficientnet-pytorch'\n",
    "\n",
    "sys.path.append(efficientnet_path)\n",
    "\n",
    "!ls /kaggle/input/timm-pretrained-efficientnet\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/timm-pretrained-efficientnet/efficientnet/efficientnet_b0_ra-3dd342df.pth /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file transforms.py\n",
    "\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=5, val_shift_limit=5, p=1),\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.RandomResizedCrop(256, 256, scale=(0.3, 0.9)),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transforms():\n",
    "    return A.Compose([\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.Resize(400, 400),\n",
    "        A.CenterCrop(256, 256),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file utils.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "class Unnormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "    '''\n",
    "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cf:            confusion matrix to be passed in\n",
    "\n",
    "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "\n",
    "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "\n",
    "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "\n",
    "    normalize:     If True, show the proportions for each category. Default is True.\n",
    "\n",
    "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                   Default is True.\n",
    "\n",
    "    xyticks:       If True, show x and y ticks. Default is True.\n",
    "\n",
    "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "\n",
    "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "\n",
    "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "\n",
    "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "\n",
    "    title:         Title for the heatmap. Default is None.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names) == cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten() / np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels, group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        # Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        # if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf) == 2:\n",
    "            # Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1, 1] / sum(cf[:, 1])\n",
    "            recall = cf[1, 1] / sum(cf[1, :])\n",
    "            f1_score = 2 * precision * recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy, precision, recall, f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize == None:\n",
    "        # Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks == False:\n",
    "        # Do not show categories if xyticks is False\n",
    "        categories = False\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def plot_image(img, label=None, ax=None):\n",
    "    img = torch.Tensor(np.array(img))\n",
    "    label_num_to_disease_map = {0: 'Cassava Bacterial Blight (CBB)',\n",
    "                                1: 'Cassava Brown Streak Disease (CBSD)',\n",
    "                                2: 'Cassava Green Mottle (CGM)',\n",
    "                                3: 'Cassava Mosaic Disease (CMD)',\n",
    "                                4: 'Healthy'}\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    ax.imshow(img.permute(2, 1, 0))\n",
    "    ax.axis('off')\n",
    "    if label is not None:\n",
    "\n",
    "        if isinstance(label, int):\n",
    "            label = label_num_to_disease_map.get(label, 0)\n",
    "        ax.set_title(f'{label}')\n",
    "\n",
    "\n",
    "def plot_label_examples(dataset, targets, target_label):\n",
    "    label_indices = np.where(targets == target_label)[0]\n",
    "\n",
    "    sample = np.random.choice(label_indices, 6)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(2, 3),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, idx in zip(grid, sample):\n",
    "        img, label = dataset[idx]\n",
    "        assert label == target_label\n",
    "        plot_image(img, ax=ax)\n",
    "    plt.suptitle(f'Label {target_label}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(image=x)['image']\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, root, image_ids, labels, transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.targets = self.labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = io.imread(os.path.join(self.root, self.image_ids[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/model.py\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from torch import nn\n",
    "import timm\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeafDoctorModel(pl.LightningModule):\n",
    "    def __init__(self, hparams = None):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams or Namespace()\n",
    "\n",
    "        self.trunk = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        probabilities = nn.functional.softmax(self.forward(x), dim=1)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, x):\n",
    "        return torch.max(self.forward(x), 1)[1]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(),\n",
    "                                      lr=self.hparams.lr or self.hparams.learning_rate,\n",
    "                                      weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  patience=self.hparams.reduce_lr_on_pleteau_patience)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "            'monitor': 'val_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True),\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file node_helpers.py\n",
    "\n",
    "def score(predictions, labels):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(predictions, labels),\n",
    "        'f1_score': f1_score(predictions, labels, average='weighted'),\n",
    "    }\n",
    "\n",
    "\n",
    "def predict(model, dataset, indices, batch_size=10, num_workers=4, transform=None):\n",
    "    transform = transform or get_test_transforms()\n",
    "    dataset = DatasetFromSubset(\n",
    "        torch.utils.data.Subset(dataset, indices=indices),\n",
    "        transform=transform)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         num_workers=num_workers,\n",
    "                                         shuffle=False)\n",
    "\n",
    "    predictions = []\n",
    "    probas = []\n",
    "    model.eval()\n",
    "    model.freeze()\n",
    "    for images, labels in tqdm(loader):\n",
    "        batch_preds = model.predict(images)\n",
    "        predictions += batch_preds.tolist()\n",
    "        probas += model.predict_proba(images).tolist()\n",
    "    return predictions, probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline train\n",
    "\n",
    "def split_data(train_labels, parameters):\n",
    "    \"\"\"Splits trainig data into the train and validation set\"\"\"\n",
    "    train_indices, val_indices = train_test_split(range(len(train_labels)),\n",
    "                     stratify=train_labels.label,\n",
    "                     random_state=parameters['seed'],\n",
    "                     test_size=parameters['validation_size'])\n",
    "    return train_indices, val_indices\n",
    "\n",
    "\n",
    "def train_model(train_images_torch, train_indices, val_indices, parameters):\n",
    "    train_transform, val_transform = get_train_transforms(), get_test_transforms()\n",
    "\n",
    "    train_dataset = DatasetFromSubset(torch.utils.data.Subset(train_images_torch, indices=train_indices),\n",
    "                                      transform=train_transform)\n",
    "\n",
    "    val_dataset = DatasetFromSubset(torch.utils.data.Subset(train_images_torch, indices=val_indices),\n",
    "                                    transform=val_transform)\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                    batch_size=parameters['batch_size'],\n",
    "                                                    num_workers=parameters['data_loader_workers'],\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_dataset, num_workers=parameters['data_loader_workers'], batch_size=parameters['batch_size'])\n",
    "\n",
    "    # Callbacks\n",
    "    model_checkpoint = ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                       verbose=True,\n",
    "                                       dirpath=parameters['checkpoints_dir'],\n",
    "                                       filename=\"{epoch}_{val_loss:.4f}\",\n",
    "                                       save_top_k=parameters['save_top_k_checkpoints'])\n",
    "    early_stopping = EarlyStopping('val_loss',\n",
    "                                   patience=parameters['early_stop_patience'],\n",
    "                                   verbose=True,\n",
    "                                   )\n",
    "\n",
    "    hparams = Namespace(**parameters)\n",
    "\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        hparams,\n",
    "        reload_dataloaders_every_epoch = True,\n",
    "        callbacks=[model_checkpoint, early_stopping],\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = LeafDoctorModel(hparams)\n",
    "\n",
    "    # LR finding\n",
    "    # lr_finder = trainer.tuner.lr_find(model,\n",
    "    #                                   train_dataloader=train_data_loader,\n",
    "    #                                   val_dataloaders=[val_data_loader])\n",
    "    # plt.figure()\n",
    "    # plt.title('LR finder results')\n",
    "    # lr_finder.plot(suggest=True)\n",
    "    # plt.show()\n",
    "    # new_lr = lr_finder.suggestion()\n",
    "    #\n",
    "    # logging.info('LR finder found this LR: %f', new_lr)\n",
    "    # model.hparams.lr = new_lr\n",
    "\n",
    "    # Training\n",
    "    trainer.fit(model, train_data_loader, val_data_loader)\n",
    "    logging.info('Training finished')\n",
    "\n",
    "    # Saving\n",
    "    best_checkpoint = model_checkpoint.best_model_path\n",
    "    model = LeafDoctorModel().load_from_checkpoint(checkpoint_path=best_checkpoint)\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_model(model, train_images_torch, indices, parameters):\n",
    "    logging.info('Scoring model')\n",
    "    labels = train_images_torch.labels[indices]\n",
    "    predictions = predict(model,\n",
    "                          dataset=train_images_torch,\n",
    "                          indices=indices,\n",
    "                          batch_size=parameters['batch_size'],\n",
    "                          num_workers=parameters['data_loader_workers'],\n",
    "                          transform=get_test_transforms())\n",
    "\n",
    "    scores = score(predictions, labels)\n",
    "\n",
    "    logging.info(f'Validation scores:\\n{scores}')\n",
    "    return scores, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline predict\n",
    "\n",
    "def predict_submission(cv_results, test_images_torch, sample_submission, parameters):\n",
    "    logging.debug('Predicting on test with model')\n",
    "\n",
    "    fold_model_names = [cv_results[fold]['model_path'] for fold in cv_results if fold != 'summary']\n",
    "\n",
    "    all_probas = []\n",
    "    for fname in fold_model_names:\n",
    "        model_path = os.path.join(parameters['cv_models_dir'], fname)\n",
    "        model = LeafDoctorModel()\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        predictions, probas = predict(model,\n",
    "                                  dataset=test_images_torch,\n",
    "                                  indices=list(range(len(test_images_torch))),\n",
    "                                  batch_size=parameters['batch_size'],\n",
    "                                  num_workers=parameters['data_loader_workers'],\n",
    "                                  transform=get_test_transforms())\n",
    "\n",
    "        all_probas.append(probas)\n",
    "\n",
    "    aggregated_probas = np.mean(all_probas, axis=0)\n",
    "    pred_labels = np.argmax(aggregated_probas, 1)\n",
    "    sample_submission.label = pred_labels\n",
    "    return sample_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline cv\n",
    "\n",
    "def cross_validation(train_images_torch, parameters):\n",
    "    cv_results = {}\n",
    "    score_values = {}\n",
    "\n",
    "    if os.path.exists(parameters['cv_models_dir']):\n",
    "        raise Exception('CV models path already exists, please delete it explicitly to overwrite')\n",
    "    else:\n",
    "        os.makedirs(parameters['cv_models_dir'])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=parameters['cv_splits'], random_state=parameters['seed'])\n",
    "    indices = np.array(list(range(len(train_images_torch))))\n",
    "    labels = train_images_torch.labels\n",
    "    for fold_num, (train_idx, val_idx) in enumerate(cv.split(indices, labels)):\n",
    "        logging.info('Fitting CV fold %d', fold_num)\n",
    "        model_path = os.path.join(parameters['cv_models_dir'], f'model_fold_{fold_num}.pt')\n",
    "        fold_parameters = copy(parameters)\n",
    "        model = train_model(train_images_torch, train_idx, val_idx, fold_parameters)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        scores, oof_predictions = score_model(model, train_images_torch, val_idx, fold_parameters)\n",
    "        cv_results[f'fold_{fold_num}'] = {\n",
    "            'model_path': model_path,\n",
    "            'scores': scores,\n",
    "            'val_indices': val_idx,\n",
    "            'oof_predictions': oof_predictions,\n",
    "        }\n",
    "\n",
    "        for score in scores:\n",
    "            if not score_values.get(score):\n",
    "                score_values[score] = []\n",
    "            score_values[score].append(scores[score])\n",
    "\n",
    "    cv_results['summary'] = {\n",
    "\n",
    "    }\n",
    "    for score_name, scores in score_values.items():\n",
    "        cv_results['summary'][f'{score_name}_mean'] = np.mean(scores)\n",
    "        cv_results['summary'][f'{score_name}_std'] = np.std(scores)\n",
    "\n",
    "    logging.info('Cross-validation results %s')\n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"seed\": 42,\n",
    "    \"validation_size\": 0.15,\n",
    "    \"gpus\": -1,\n",
    "    \"data_loader_workers\": 6,\n",
    "    \"batch_size\": 10,\n",
    "    \"max_epochs\": 100,\n",
    "    \"max_steps\": 0,\n",
    "    \"auto_lr_find\": 0,\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0.0001,\n",
    "    \"early_stop_patience\": 4,\n",
    "    \"reduce_lr_on_pleteau_patience\": 2,\n",
    "    \"save_top_k_checkpoints\": 1,\n",
    "    \"checkpoints_dir\": \"data/06_models/checkpoints\",\n",
    "    \"cv_splits\": 3,\n",
    "    \"cv_models_dir\": \"data/06_models/cv_folds\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = '/kaggle/input/cassava-leaf-disease-classification'\n",
    "\n",
    "train_labels = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "sample_submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "label_num_to_disease_map = pd.read_csv(f'{DATA_DIR}/label_num_to_disease_map.json')\n",
    "\n",
    "train_images_torch = CassavaDataset(image_ids=train_labels.image_id.values, labels=train_labels.label.values, root=f'{DATA_DIR}/train_images')\n",
    "test_images_torch = CassavaDataset(image_ids=sample_submission.image_id.values, labels=sample_submission.label.values, root=f'{DATA_DIR}/test_images')\n",
    "\n",
    "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predict_submission(cv_results, test_images_torch, sample_submission, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validation(train_images_torch, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(print(cv_results['summary']))\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
