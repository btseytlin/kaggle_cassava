{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imagehash\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "from skimage.io import imsave\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from copy import copy\n",
    "from pytorch_lightning import Trainer\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, ConcatDataset\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import pandas as pd\n",
    "from torch.utils.data import ConcatDataset, Subset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import sys\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ls /kaggle/input/timm-pretrained-efficientnet\n",
    "!mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/timm-pretrained-efficientnet/efficientnet/efficientnet_b0_ra-3dd342df.pth /root/.cache/torch/hub/checkpoints/efficientnet_b0_ra-3dd342df.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install /kaggle/input/timm-package/timm-0.1.26-py3-none-any.whl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file transforms.py\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision import transforms\n",
    "\n",
    "byol_transforms = A.Compose([\n",
    "    A.ToFloat(max_value=1.0),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "lmdb_transforms = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "])\n",
    "\n",
    "\n",
    "def get_train_transforms():\n",
    "    return A.Compose([\n",
    "        A.HueSaturationValue(hue_shift_limit=5, sat_shift_limit=5, val_shift_limit=5, p=0.5),\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.RandomResizedCrop(350, 350, scale=(0.1, 0.8), ratio=(8/6, 8/6)),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_test_transforms():\n",
    "    return A.Compose([\n",
    "        A.ToFloat(max_value=1.0),\n",
    "        A.CenterCrop(350, 350),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file utils.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from skimage import io\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "class Unnormalize:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "def make_confusion_matrix(cf,\n",
    "                          group_names=None,\n",
    "                          categories='auto',\n",
    "                          count=True,\n",
    "                          percent=True,\n",
    "                          cbar=True,\n",
    "                          xyticks=True,\n",
    "                          xyplotlabels=True,\n",
    "                          sum_stats=True,\n",
    "                          figsize=None,\n",
    "                          cmap='Blues',\n",
    "                          title=None):\n",
    "\n",
    "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "    blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "    if group_names and len(group_names) == cf.size:\n",
    "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "    else:\n",
    "        group_labels = blanks\n",
    "\n",
    "    if count:\n",
    "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "    else:\n",
    "        group_counts = blanks\n",
    "\n",
    "    if percent:\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten() / np.sum(cf)]\n",
    "    else:\n",
    "        group_percentages = blanks\n",
    "\n",
    "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels, group_counts, group_percentages)]\n",
    "    box_labels = np.asarray(box_labels).reshape(cf.shape[0], cf.shape[1])\n",
    "\n",
    "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "    if sum_stats:\n",
    "        # Accuracy is sum of diagonal divided by total observations\n",
    "        accuracy = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "        # if it is a binary confusion matrix, show some more stats\n",
    "        if len(cf) == 2:\n",
    "            # Metrics for Binary Confusion Matrices\n",
    "            precision = cf[1, 1] / sum(cf[:, 1])\n",
    "            recall = cf[1, 1] / sum(cf[1, :])\n",
    "            f1_score = 2 * precision * recall / (precision + recall)\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n",
    "                accuracy, precision, recall, f1_score)\n",
    "        else:\n",
    "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "    else:\n",
    "        stats_text = \"\"\n",
    "\n",
    "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "    if figsize == None:\n",
    "        # Get default figure size if not set\n",
    "        figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "    if xyticks == False:\n",
    "        # Do not show categories if xyticks is False\n",
    "        categories = False\n",
    "\n",
    "    # MAKE THE HEATMAP VISUALIZATION\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cf, annot=box_labels, fmt=\"\", cmap=cmap, cbar=cbar, xticklabels=categories, yticklabels=categories)\n",
    "\n",
    "    if xyplotlabels:\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label' + stats_text)\n",
    "    else:\n",
    "        plt.xlabel(stats_text)\n",
    "\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def plot_image(img, label=None, ax=None):\n",
    "    img = torch.Tensor(np.array(img))\n",
    "    label_num_to_disease_map = {0: 'Cassava Bacterial Blight (CBB)',\n",
    "                                1: 'Cassava Brown Streak Disease (CBSD)',\n",
    "                                2: 'Cassava Green Mottle (CGM)',\n",
    "                                3: 'Cassava Mosaic Disease (CMD)',\n",
    "                                4: 'Healthy'}\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "    ax.imshow(img.permute(2, 1, 0))\n",
    "    ax.axis('off')\n",
    "    if label is not None:\n",
    "\n",
    "        if isinstance(label, int):\n",
    "            label = label_num_to_disease_map.get(label, 0)\n",
    "        ax.set_title(f'{label}')\n",
    "\n",
    "\n",
    "def plot_label_examples(dataset, targets, target_label):\n",
    "    label_indices = np.where(targets == target_label)[0]\n",
    "\n",
    "    sample = np.random.choice(label_indices, 6)\n",
    "\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                     nrows_ncols=(2, 3),  # creates 2x2 grid of axes\n",
    "                     axes_pad=0.1,  # pad between axes in inch.\n",
    "                     )\n",
    "\n",
    "    for ax, idx in zip(grid, sample):\n",
    "        img, label = dataset[idx]\n",
    "        assert label == target_label\n",
    "        plot_image(img, ax=ax)\n",
    "    plt.suptitle(f'Label {target_label}')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class DatasetFromSubset(Dataset):\n",
    "    def __init__(self, subset, transform=None, target_transform=None):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.subset[index]\n",
    "        if self.transform:\n",
    "            x = self.transform(image=np.array(x))['image']\n",
    "\n",
    "        if self.target_transform:\n",
    "            y = self.target_transform(y)\n",
    "        return x, y\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self.subset.dataset.labels[self.subset.indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "\n",
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, root, image_ids, labels, sources=None, transform=None):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.image_ids = image_ids\n",
    "        self.labels = labels\n",
    "        self.targets = self.labels\n",
    "        self.sources = sources\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        img = io.imread(os.path.join(self.root, self.image_ids[idx]))\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "def make_2019_like_2020(image):\n",
    "    \"\"\"Transforms a PIL Image to have aspec ratio 8/6\"\"\"\n",
    "    if image.size[0] < image.size[1]:\n",
    "        image = image.rotate(90, expand=True)\n",
    "\n",
    "    # Center crop until 8:6\n",
    "    width, height = image.size   # Get dimensions\n",
    "    new_height = int(height*(width/height * 6/8))\n",
    "    new_width = width\n",
    "\n",
    "    left = (width - new_width)/2\n",
    "    top = (height - new_height)/2\n",
    "    right = (width + new_width)/2\n",
    "    bottom = (height + new_height)/2\n",
    "\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/model.py\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning.metrics.functional import accuracy\n",
    "from torch import nn\n",
    "import timm\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class LeafDoctorModel(pl.LightningModule):\n",
    "    def __init__(self, hparams = None):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams or Namespace()\n",
    "\n",
    "        self.trunk = timm.create_model('efficientnet_b0', pretrained=True, num_classes=5)\n",
    "\n",
    "        for layer in [self.trunk.bn1, self.trunk.bn2]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.trunk(x)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        probabilities = nn.functional.softmax(self.forward(x), dim=1)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(self, x):\n",
    "        return torch.max(self.forward(x), 1)[1]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, self.parameters()),\n",
    "                                      lr=self.hparams.lr or self.hparams.learning_rate,\n",
    "                                      weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  patience=self.hparams.reduce_lr_on_pleteau_patience,\n",
    "                                                                  verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "            'monitor': 'val_acc',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = accuracy(y_hat, y)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True, logger=True),\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file models/byol.py\n",
    "\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "from copy import deepcopy\n",
    "from itertools import chain\n",
    "from typing import Dict, List\n",
    "import pytorch_lightning as pl\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch import optim\n",
    "import torch.nn.functional as f\n",
    "import random\n",
    "from typing import Callable, Tuple, Union\n",
    "from kornia import augmentation as aug\n",
    "from kornia import filters\n",
    "from kornia.geometry import transform as tf\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "def normalized_mse(x: Tensor, y: Tensor) -> Tensor:\n",
    "    x = f.normalize(x, dim=-1)\n",
    "    y = f.normalize(y, dim=-1)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "\n",
    "\n",
    "class RandomApply(nn.Module):\n",
    "    def __init__(self, fn: Callable, p: float):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return x if random.random() > self.p else self.fn(x)\n",
    "\n",
    "\n",
    "def default_aug(image_size: Tuple[int, int] = (512, 512)) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        aug.ColorJitter(contrast=0.1, brightness=0.1, saturation=0.1, p=0.8),\n",
    "        aug.RandomVerticalFlip(),\n",
    "        aug.RandomHorizontalFlip(),\n",
    "        RandomApply(filters.GaussianBlur2d((3, 3), (0.5, 0.5)), p=0.1),\n",
    "        aug.RandomResizedCrop(size=image_size, scale=(0.5, 1)),\n",
    "        aug.Normalize(\n",
    "            mean=torch.tensor([0.485, 0.456, 0.406]),\n",
    "            std=torch.tensor([0.229, 0.224, 0.225]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def mlp(dim: int, projection_size: int = 256, hidden_size: int = 4096) -> nn.Module:\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(dim, hidden_size),\n",
    "        nn.BatchNorm1d(hidden_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(hidden_size, projection_size),\n",
    "    )\n",
    "\n",
    "\n",
    "class EncoderWrapper(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        layer: Union[str, int] = -2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.projection_size = projection_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.layer = layer\n",
    "\n",
    "        self._projector = None\n",
    "        self._projector_dim = None\n",
    "        self._encoded = torch.empty(0)\n",
    "        self._register_hook()\n",
    "\n",
    "    @property\n",
    "    def projector(self):\n",
    "        if self._projector is None:\n",
    "            self._projector = mlp(\n",
    "                self._projector_dim, self.projection_size, self.hidden_size\n",
    "            )\n",
    "        return self._projector\n",
    "\n",
    "    def _hook(self, _, __, output):\n",
    "        output = output.flatten(start_dim=1)\n",
    "        if self._projector_dim is None:\n",
    "            self._projector_dim = output.shape[-1]\n",
    "        self._encoded = self.projector(output)\n",
    "\n",
    "    def _register_hook(self):\n",
    "        if isinstance(self.layer, str):\n",
    "            layer = dict([*self.model.named_modules()])[self.layer]\n",
    "        else:\n",
    "            layer = list(self.model.children())[self.layer]\n",
    "\n",
    "        layer.register_forward_hook(self._hook)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        _ = self.model(x)\n",
    "        return self._encoded\n",
    "\n",
    "\n",
    "class BYOL(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        image_size: Tuple[int, int] = (512, 512),\n",
    "        hidden_layer: Union[str, int] = -2,\n",
    "        projection_size: int = 256,\n",
    "        hidden_size: int = 4096,\n",
    "        augment_fn: Callable = None,\n",
    "        beta: float = 0.99,\n",
    "        hparams = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._augment = default_aug(image_size) if augment_fn is None else augment_fn\n",
    "        self.beta = beta\n",
    "        self.encoder = EncoderWrapper(\n",
    "            model, projection_size, hidden_size, layer=hidden_layer\n",
    "        )\n",
    "        self.predictor = nn.Linear(projection_size, projection_size, hidden_size)\n",
    "        self.hparams = hparams or Namespace()\n",
    "        self._target = None\n",
    "\n",
    "        self.encoder(torch.zeros(2, 3, *image_size))\n",
    "\n",
    "    def augment(self, batch):\n",
    "        if self.hparams.precision == 16:\n",
    "            return self._augment(batch.double()).to(torch.float16)\n",
    "        return self._augment(batch)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.predictor(self.encoder(x))\n",
    "\n",
    "    @property\n",
    "    def target(self):\n",
    "        if self._target is None:\n",
    "            self._target = deepcopy(self.encoder)\n",
    "        return self._target\n",
    "\n",
    "    def update_target(self):\n",
    "        for p, pt in zip(self.encoder.parameters(), self.target.parameters()):\n",
    "            pt.data = self.beta * pt.data + (1 - self.beta) * p.data\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                                  patience=self.hparams.reduce_lr_on_pleteau_patience,\n",
    "                                                                  verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "            'monitor': 'train_loss',\n",
    "            'interval': 'epoch',\n",
    "            'frequency': 1\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        with torch.no_grad():\n",
    "            x1, x2 = self.augment(x), self.augment(x)\n",
    "\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        with torch.no_grad():\n",
    "            targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        self.log(\"train_loss\", loss.item())\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_step(self, batch, *_) -> Dict[str, Union[Tensor, Dict]]:\n",
    "        x = batch[0]\n",
    "        x1, x2 = self.augment(x), self.augment(x)\n",
    "        pred1, pred2 = self.forward(x1), self.forward(x2)\n",
    "        targ1, targ2 = self.target(x1), self.target(x2)\n",
    "        loss = torch.mean(normalized_mse(pred1, targ2) + normalized_mse(pred2, targ1))\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def validation_epoch_end(self, outputs: List[Dict]) -> Dict:\n",
    "        val_loss = sum(x[\"loss\"] for x in outputs) / len(outputs)\n",
    "        self.log(\"val_loss\", val_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file node_helpers.py\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def score(predictions, labels):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(predictions, labels),\n",
    "        'f1_score': f1_score(predictions, labels, average='weighted'),\n",
    "    }\n",
    "\n",
    "\n",
    "def predict(model, dataset, indices, batch_size=10, num_workers=4, transform=None):\n",
    "    transform = transform or get_test_transforms()\n",
    "    dataset = DatasetFromSubset(\n",
    "        Subset(dataset, indices=indices),\n",
    "        transform=transform)\n",
    "\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=num_workers,\n",
    "                        shuffle=False,\n",
    "                        drop_last=False)\n",
    "\n",
    "    predictions = []\n",
    "    probas = []\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader):\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "            batch_probas = model.predict_proba(images)\n",
    "            batch_preds = torch.max(batch_probas, 1)[1]\n",
    "            predictions.append(batch_preds)\n",
    "            probas.append(batch_probas)\n",
    "\n",
    "    predictions = torch.hstack(predictions).flatten().tolist()\n",
    "    probas = torch.vstack(probas).tolist()\n",
    "\n",
    "    return predictions, probas\n",
    "\n",
    "\n",
    "def lr_find(trainer, model, train_data_loader, val_data_loader=None, plot=False):\n",
    "    val_dataloaders = [val_data_loader] if val_data_loader else None\n",
    "\n",
    "    lr_finder = trainer.tuner.lr_find(model,\n",
    "                                      train_dataloader=train_data_loader,\n",
    "                                      val_dataloaders=val_dataloaders)\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.title('LR finder results')\n",
    "        lr_finder.plot(suggest=True)\n",
    "        plt.show()\n",
    "\n",
    "    newlr = lr_finder.suggestion()\n",
    "    logging.info('LR finder suggestion: %f', newlr)\n",
    "\n",
    "    return newlr\n",
    "\n",
    "\n",
    "def train_byol(model, hparams, loader):\n",
    "    byol = BYOL(model, image_size=(512, 512), hparams=hparams)\n",
    "\n",
    "    early_stopping = EarlyStopping('train_loss',\n",
    "                                   mode='min',\n",
    "                                   patience=hparams.early_stop_patience,\n",
    "                                   verbose=True)\n",
    "\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        hparams,\n",
    "        reload_dataloaders_every_epoch=True,\n",
    "        terminate_on_nan=True,\n",
    "        callbacks=[early_stopping],\n",
    "        precision=hparams.precision,\n",
    "        amp_level=hparams.amp_level,\n",
    "    )\n",
    "\n",
    "    if hparams.auto_lr_find:\n",
    "        new_lr = lr_find(trainer, byol, loader)\n",
    "        hparams.lr = new_lr\n",
    "        byol.hparams.lr = new_lr\n",
    "\n",
    "    trainer.fit(byol, loader, loader)\n",
    "    return byol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline prepare\n",
    "\n",
    "def obtain_image_hashes(train_images_torch_2020, train_images_torch_2019, test_images_torch_2019, extra_images_torch_2019):\n",
    "    # Adapted from https://www.kaggle.com/zzy990106/duplicate-images-in-two-competitions\n",
    "    datasets = {\n",
    "        'train_2020': train_images_torch_2020,\n",
    "        'train_2019': train_images_torch_2019,\n",
    "        'test_2019': test_images_torch_2019,\n",
    "        'extra_2019': extra_images_torch_2019,\n",
    "    }\n",
    "\n",
    "    image_ids = []\n",
    "    hashes = []\n",
    "\n",
    "    logging.info('Obtaining hashes')\n",
    "\n",
    "    for dname, ds in tqdm(datasets.items()):\n",
    "        loader = DataLoader(ds, num_workers=6, batch_size=None)\n",
    "        for ix, (image, label) in tqdm(enumerate(loader), total=len(loader), desc=dname):\n",
    "            if dname in ['test_2019', 'extra_2019']:\n",
    "                label = None\n",
    "\n",
    "            if label is not None:\n",
    "                label = int(label)\n",
    "            img_id = (dname, ix, label)\n",
    "            pil_img = Image.fromarray(np.array(image))\n",
    "            hash = get_img_hash(pil_img)\n",
    "            image_ids.append(img_id)\n",
    "            hashes.append(hash)\n",
    "\n",
    "    image_ids_df = pd.DataFrame(image_ids, columns=['ds', 'ix', 'label'])\n",
    "    hashes_df = pd.DataFrame(np.array(hashes).astype(int))\n",
    "\n",
    "    return image_ids_df, hashes_df\n",
    "\n",
    "\n",
    "def find_duplicates(image_ids, image_hashes):\n",
    "    # Adapted from https://www.kaggle.com/zzy990106/duplicate-images-in-two-competitions\n",
    "    image_ids = image_ids.values\n",
    "    hashes = image_hashes.values\n",
    "\n",
    "    hashes_all = np.array(hashes)\n",
    "    hashes_all = torch.Tensor(hashes_all.astype(int))\n",
    "\n",
    "    logging.info('Computing similarities and finding duplicates')\n",
    "    sim_threshold = int(0.9 * hashes_all.shape[1])\n",
    "    duplicates = []\n",
    "    for i in tqdm(range(hashes_all.shape[0])):\n",
    "        sim = ((hashes_all[i] == hashes_all).sum(dim=1).numpy() > sim_threshold).astype(int)\n",
    "        dupes = np.nonzero(sim)[0]\n",
    "        if len(dupes) > 1:\n",
    "            for dup in dupes:\n",
    "                if dup != i:\n",
    "                    duplicates.append(tuple(sorted([i, dup])))\n",
    "\n",
    "    duplicates = list(set(duplicates))\n",
    "\n",
    "    out_rows = []\n",
    "    for duplicate_pair in duplicates:\n",
    "        image_id1 = image_ids[duplicate_pair[0]]\n",
    "        image_id2 = image_ids[duplicate_pair[1]]\n",
    "        out_rows.append(\n",
    "            # ds1 | id1 | label1 | ds2 | id2 | label2\n",
    "            (*image_id1, *image_id2)\n",
    "        )\n",
    "\n",
    "    out_rows = pd.DataFrame(list(set(out_rows)), columns=['ds1', 'id1', 'label1', 'ds2', 'id2', 'label2'])\n",
    "    return out_rows\n",
    "\n",
    "\n",
    "def prepare_dataset(train_images_torch_2020, train_images_torch_2019, test_images_torch_2019, extra_images_torch_2019, duplicates):\n",
    "    blacklist = dict(duplicates[['ds2', 'id2']].groupby('ds2').agg({'id2': list})['id2'])\n",
    "\n",
    "    train_images_torch_2019.transform = make_2019_like_2020\n",
    "    test_images_torch_2019.transform = make_2019_like_2020\n",
    "    extra_images_torch_2019.transform = make_2019_like_2020\n",
    "\n",
    "    train_dataset_2020 = DatasetFromSubset(\n",
    "        Subset(train_images_torch_2020, indices=[i for i in range(len(train_images_torch_2020)) if i not in blacklist['train_2020']]),\n",
    "        transform=lmdb_transforms)\n",
    "\n",
    "    train_dataset_2019 = DatasetFromSubset(\n",
    "        Subset(train_images_torch_2019,\n",
    "               indices=[i for i in range(len(train_images_torch_2019)) if i not in blacklist['train_2019']]),\n",
    "        transform=lmdb_transforms)\n",
    "\n",
    "    test_dataset_2019 = DatasetFromSubset(\n",
    "        Subset(test_images_torch_2019,\n",
    "               indices=[i for i in range(len(test_images_torch_2019)) if i not in blacklist['test_2019']]),\n",
    "        transform=lmdb_transforms, target_transform=lambda y: -1)\n",
    "\n",
    "    extra_images_torch_2019 = DatasetFromSubset(\n",
    "        Subset(extra_images_torch_2019,\n",
    "               indices=[i for i in range(len(extra_images_torch_2019)) if i not in blacklist['extra_2019']]),\n",
    "        transform=lmdb_transforms, target_transform=lambda y: -1)\n",
    "\n",
    "    train_dataset = ConcatDataset([train_dataset_2020, train_dataset_2019])\n",
    "    train_sources = ['train_2020']*len(train_dataset_2020) + ['train_2019']*len(train_dataset_2019)\n",
    "\n",
    "    unlabelled_dataset = ConcatDataset([test_dataset_2019, extra_images_torch_2019])\n",
    "    unlabelled_sources = ['test_2019'] * len(test_dataset_2019) + ['extra_2019'] * len(extra_images_torch_2019)\n",
    "\n",
    "    train_path = 'data/03_primary/train'\n",
    "    train_csv_path = 'data/03_primary/train.csv'\n",
    "    unlabelled_path = 'data/03_primary/unlabelled'\n",
    "    unlabelled_csv_path = 'data/03_primary/unlabelled.csv'\n",
    "\n",
    "    if any([os.path.exists(train_path),\n",
    "            os.path.exists(unlabelled_path)]):\n",
    "        raise Exception('Dataset folders already exist, delete manually to overwrite.')\n",
    "\n",
    "    os.makedirs(train_path, exist_ok=True)\n",
    "    os.makedirs(unlabelled_path, exist_ok=True)\n",
    "\n",
    "    def make_image_folder(dataset, sources, path, csv_path):\n",
    "        loader = DataLoader(dataset, batch_size=None, num_workers=6, collate_fn=lambda x: x)\n",
    "        rows = []\n",
    "        for ix, (image, label) in enumerate(tqdm(loader)):\n",
    "            image_id = f'{ix}.jpg'\n",
    "            source = sources[ix]\n",
    "            img_path = os.path.join(path, image_id)\n",
    "            imsave(img_path, image)\n",
    "            rows.append((image_id, label, source))\n",
    "\n",
    "        df = pd.DataFrame(rows, columns=['image_id', 'label', 'source'])\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        return df\n",
    "\n",
    "    train_df = make_image_folder(train_dataset, train_sources, train_path, train_csv_path)\n",
    "    unlabelled_df = make_image_folder(unlabelled_dataset, unlabelled_sources, unlabelled_path, unlabelled_csv_path)\n",
    "    return CassavaDataset(train_path, train_df.image_id, train_df.label), CassavaDataset(unlabelled_path, unlabelled_df.image_id, unlabelled_df.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline pretrain\n",
    "\n",
    "def pretrain_model(train, unlabelled, parameters):\n",
    "    train_dataset = DatasetFromSubset(\n",
    "        Subset(train, indices=list(range(len(train)))),\n",
    "        transform=byol_transforms)\n",
    "    unlabelled_dataset = DatasetFromSubset(\n",
    "        Subset(unlabelled, indices=list(range(len(unlabelled)))),\n",
    "        transform=byol_transforms)\n",
    "    dataset = ConcatDataset([train_dataset, unlabelled_dataset])\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=parameters['byol']['batch_size'],\n",
    "                        num_workers=parameters['data_loader_workers'],\n",
    "                        shuffle=True)\n",
    "\n",
    "    classifier_params = Namespace(**parameters['classifier'])\n",
    "    model = LeafDoctorModel(classifier_params)\n",
    "\n",
    "    hparams = Namespace(**parameters['byol'])\n",
    "    byol = train_byol(model.trunk, hparams, loader)\n",
    "\n",
    "    state_dict = byol.encoder.model.state_dict()\n",
    "    model = LeafDoctorModel(classifier_params)\n",
    "    model.trunk.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline train\n",
    "\n",
    "def split_data(train, parameters):\n",
    "    \"\"\"Splits trainig data into the train and validation set\"\"\"\n",
    "    labels = train.labels\n",
    "    train_indices, val_indices = train_test_split(range(len(labels)),\n",
    "                     stratify=labels,\n",
    "                     random_state=parameters['seed'],\n",
    "                     test_size=parameters['validation_size'])\n",
    "    return train_indices, val_indices\n",
    "\n",
    "\n",
    "def train_model(finetuned_model, train, train_indices, val_indices, parameters):\n",
    "    train_transform, val_transform = get_train_transforms(), get_test_transforms()\n",
    "\n",
    "    train_dataset = DatasetFromSubset(Subset(train, indices=train_indices),\n",
    "                                      transform=train_transform)\n",
    "\n",
    "    val_dataset = DatasetFromSubset(Subset(train, indices=val_indices),\n",
    "                                    transform=val_transform)\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset,\n",
    "                                                    batch_size=parameters['classifier']['batch_size'],\n",
    "                                                    num_workers=parameters['data_loader_workers'],\n",
    "                                                    shuffle=True)\n",
    "\n",
    "    val_data_loader = DataLoader(val_dataset,\n",
    "                                                  batch_size=parameters['classifier']['batch_size'],\n",
    "                                                  num_workers=parameters['data_loader_workers'])\n",
    "\n",
    "    # Callbacks\n",
    "    model_checkpoint = ModelCheckpoint(monitor=\"val_acc\",\n",
    "                                       mode='max',\n",
    "                                       verbose=True,\n",
    "                                       dirpath=parameters['classifier']['checkpoints_dir'],\n",
    "                                       filename=\"{epoch}_{val_acc:.4f}\",\n",
    "                                       save_top_k=parameters['classifier']['save_top_k_checkpoints'])\n",
    "    early_stopping = EarlyStopping('val_acc',\n",
    "                                   mode='max',\n",
    "                                   patience=parameters['classifier']['early_stop_patience'],\n",
    "                                   verbose=True,\n",
    "                                   )\n",
    "\n",
    "    hparams = Namespace(**parameters['classifier'])\n",
    "\n",
    "    trainer = Trainer.from_argparse_args(\n",
    "        hparams,\n",
    "        reload_dataloaders_every_epoch = True,\n",
    "        terminate_on_nan=True,\n",
    "        callbacks=[model_checkpoint, early_stopping],\n",
    "        precision=hparams.precision,\n",
    "        amp_level=hparams.amp_level,\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    model = LeafDoctorModel(hparams)\n",
    "    model.load_state_dict(finetuned_model.state_dict())\n",
    "\n",
    "    # Training\n",
    "    trainer.fit(model, train_data_loader, val_data_loader)\n",
    "    logging.info('Training finished')\n",
    "\n",
    "    # Saving\n",
    "    best_checkpoint = model_checkpoint.best_model_path\n",
    "    model = LeafDoctorModel(hparams).load_from_checkpoint(checkpoint_path=best_checkpoint)\n",
    "    return model\n",
    "\n",
    "\n",
    "def score_model(model, train, indices, parameters):\n",
    "    logging.info('Scoring model')\n",
    "    if parameters['classifier'].get('limit_val_batches'):\n",
    "        indices = indices[:parameters['classifier']['limit_val_batches']*parameters['classifier']['batch_size']]\n",
    "    labels = np.array(train.labels)[indices]\n",
    "    predictions, probas = predict(model,\n",
    "                          dataset=train,\n",
    "                          indices=indices,\n",
    "                          batch_size=parameters['eval']['batch_size'],\n",
    "                          num_workers=parameters['data_loader_workers'],\n",
    "                          transform=get_test_transforms())\n",
    "\n",
    "    scores = score(predictions, labels)\n",
    "\n",
    "    logging.info(f'Validation scores:\\n{scores}')\n",
    "    return scores, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline predict\n",
    "\n",
    "def predict_submission(cv_results, test_images_torch_2020, sample_submission, parameters):\n",
    "    logging.debug('Predicting on test with model')\n",
    "\n",
    "    fold_model_names = [cv_results[fold]['model_path'] for fold in cv_results if fold != 'summary']\n",
    "\n",
    "    all_probas = []\n",
    "    for model_path in fold_model_names:\n",
    "        model = LeafDoctorModel()\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "        predictions, probas = predict(model,\n",
    "                                  dataset=test_images_torch_2020,\n",
    "                                  indices=list(range(len(test_images_torch_2020))),\n",
    "                                  batch_size=parameters['eval']['batch_size'],\n",
    "                                  num_workers=parameters['data_loader_workers'],\n",
    "                                  transform=get_test_transforms())\n",
    "\n",
    "        all_probas.append(probas)\n",
    "\n",
    "    aggregated_probas = np.mean(all_probas, axis=0).reshape(-1, 5)\n",
    "    pred_labels = np.argmax(aggregated_probas, 1)\n",
    "    sample_submission.label = pred_labels\n",
    "    return sample_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline cv\n",
    "\n",
    "def obtain_cv_splits(train, parameters):\n",
    "    labels = train.labels\n",
    "    sources = train.sources\n",
    "    indices_2020 = np.argwhere(sources == 'train_2020').flatten()\n",
    "    indices_2019 = np.argwhere(sources == 'train_2019').flatten()\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=parameters['cv_splits'], random_state=parameters['seed'])\n",
    "\n",
    "    splits = []\n",
    "    # Preserve same class distribution in both train and test\n",
    "    # Only put 2020 data in test\n",
    "    splits_2019 = list(cv.split(indices_2019, labels[indices_2020][:len(indices_2019)]))\n",
    "    splits_2020 = list(cv.split(indices_2020, labels[indices_2020]))\n",
    "    for (train_2019_idx, test_2019_idx), (train_2020_idx, test_2020_idx) in zip(splits_2019, splits_2020):\n",
    "        train_idx = np.concatenate([indices_2019[train_2019_idx], indices_2020[train_2020_idx]])\n",
    "        test_idx = indices_2020[test_2020_idx]\n",
    "        splits.append((train_idx, test_idx))\n",
    "    return splits\n",
    "\n",
    "\n",
    "def cross_validation(train, unlabelled, cv_splits, parameters):\n",
    "    cv_results = {\n",
    "        'summary': {},\n",
    "    }\n",
    "    score_values = {\n",
    "        'test': defaultdict(list),\n",
    "        'val': defaultdict(list),\n",
    "    }\n",
    "\n",
    "    if os.path.exists(parameters['cv_models_dir']) and len(os.listdir(parameters['cv_models_dir'])) > 0:\n",
    "        raise Exception('CV models path already exists, please delete it explicitly to overwrite')\n",
    "    else:\n",
    "        os.makedirs(parameters['cv_models_dir'], exist_ok=True)\n",
    "\n",
    "    for fold_num, (train_idx, test_idx) in enumerate(cv_splits):\n",
    "        logging.info('Fitting CV fold %d', fold_num)\n",
    "        model_path = os.path.join(parameters['cv_models_dir'], f'model_fold_{fold_num}.pt')\n",
    "        fold_parameters = copy(parameters)\n",
    "\n",
    "        fold_train_dataset = DatasetFromSubset(Subset(train, indices=train_idx))\n",
    "        fold_test_dataset = DatasetFromSubset(Subset(train, indices=test_idx))\n",
    "\n",
    "        # Split\n",
    "        fold_train_idx, fold_val_idx = split_data(fold_train_dataset, fold_parameters)\n",
    "        global_train_idx = train_idx[fold_train_idx]\n",
    "        global_val_idx = train_idx[fold_val_idx]\n",
    "\n",
    "        # Assert no leakage of test into train\n",
    "        assert not bool(set(global_train_idx).intersection(set(global_val_idx)))\n",
    "        assert not bool(set(global_train_idx).union(set(global_val_idx)).intersection(set(test_idx)))\n",
    "\n",
    "        logging.info('Pretraining on train+unlabelled')\n",
    "        pretrained_model = pretrain_model(fold_train_dataset, unlabelled, fold_parameters)\n",
    "\n",
    "        logging.info('Training on train, early stopping using val')\n",
    "        model = train_model(pretrained_model, fold_train_dataset, fold_train_idx, fold_val_idx, fold_parameters)\n",
    "\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "        # Score on validation\n",
    "        val_scores, val_predictions = score_model(model, fold_train_dataset, fold_val_idx, fold_parameters)\n",
    "\n",
    "        # Score on test\n",
    "        test_scores, test_predictions = score_model(model, fold_test_dataset, list(range(len(fold_test_dataset))), fold_parameters)\n",
    "\n",
    "        cv_results[f'fold_{fold_num}'] = {\n",
    "            'model_path': model_path,\n",
    "            'val_indices': global_val_idx,\n",
    "            'test_indices': test_idx,\n",
    "            'val_scores': val_scores,\n",
    "            'val_predictions': val_predictions,\n",
    "            'test_scores': test_scores,\n",
    "            'test_predictions': test_predictions,\n",
    "        }\n",
    "\n",
    "        for score in test_scores:\n",
    "            score_values['test'][score].append(test_scores[score])\n",
    "            score_values['val'][score].append(val_scores[score])\n",
    "\n",
    "    for score_set in score_values:\n",
    "        for score_name, scores in score_values[score_set].items():\n",
    "            cv_results['summary'][f'{score_set}_{score_name}_mean'] = np.mean(scores)\n",
    "            cv_results['summary'][f'{score_set}_{score_name}_std'] = np.std(scores)\n",
    "\n",
    "    logging.info('Cross-validation results %s', cv_results['summary'])\n",
    "    return cv_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline finetune\n",
    "\n",
    "def finetune_on_test(pretrained_model, train_images_lmdb, test_images_torch_2020, parameters):\n",
    "    dataset = torch.utils.data.ConcatDataset([train_images_lmdb, test_images_torch_2020])\n",
    "    dataset = DatasetFromSubset(\n",
    "        torch.utils.data.Subset(dataset, indices=list(range(len(dataset)))),\n",
    "        transform = byol_transforms)\n",
    "    loader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=parameters['byol']['batch_size'],\n",
    "                                         num_workers=parameters['data_loader_workers'],\n",
    "                                         shuffle=True)\n",
    "\n",
    "    byol_params = dict(parameters['byol'])\n",
    "    byol_test_overrides = dict(parameters['byol']['on_test'])\n",
    "    byol_params.update(byol_test_overrides)\n",
    "\n",
    "    hparams = Namespace(**byol_params)\n",
    "\n",
    "    state_dict = pretrained_model.state_dict()\n",
    "    model = LeafDoctorModel(Namespace(**parameters['classifier']))\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    byol = train_byol(pretrained_model.trunk, hparams, loader)\n",
    "\n",
    "    state_dict = byol.encoder.model.state_dict()\n",
    "    model = LeafDoctorModel(Namespace(**parameters['classifier']))\n",
    "    model.trunk.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"seed\": 42,\n",
    "    \"cv_splits\": 4,\n",
    "    \"cv_models_dir\": \"data/06_models/cv_folds\",\n",
    "    \"validation_size\": 0.15,\n",
    "    \"data_loader_workers\": 4,\n",
    "    \"classifier\": {\n",
    "        \"gpus\": -1,\n",
    "        \"batch_size\": 24,\n",
    "        \"max_epochs\": 100,\n",
    "        \"max_steps\": 0,\n",
    "        \"auto_lr_find\": 0,\n",
    "        \"lr\": 0.001,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"early_stop_patience\": 4,\n",
    "        \"reduce_lr_on_pleteau_patience\": 2,\n",
    "        \"save_top_k_checkpoints\": 1,\n",
    "        \"checkpoints_dir\": \"data/06_models/classifier/checkpoints\",\n",
    "        \"amp_level\": \"O2\",\n",
    "        \"precision\": 16\n",
    "    },\n",
    "    \"byol\": {\n",
    "        \"gpus\": -1,\n",
    "        \"batch_size\": 6,\n",
    "        \"accumulate_grad_batches\": 1,\n",
    "        \"max_epochs\": 100,\n",
    "        \"max_steps\": 0,\n",
    "        \"auto_lr_find\": 0,\n",
    "        \"lr\": 0.001,\n",
    "        \"reduce_lr_on_pleteau_patience\": 1,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"limit_train_batches\": 100,\n",
    "        \"limit_val_batches\": 1,\n",
    "        \"early_stop_patience\": 3,\n",
    "        \"amp_level\": \"02\",\n",
    "        \"precision\": 16,\n",
    "        \"on_test\": {\n",
    "            \"lr\": 0.0001,\n",
    "            \"auto_lr_find\": 0,\n",
    "            \"max_epochs\": 5,\n",
    "            \"early_stop_patience\": 1\n",
    "        }\n",
    "    },\n",
    "    \"eval\": {\n",
    "        \"batch_size\": 16\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_DIR = '/kaggle/input/cassava-leaf-disease-classification'\n",
    "MODELS_DIR = '/kaggle/input/cassava-models'\n",
    "\n",
    "train_labels = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "sample_submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "label_num_to_disease_map = pd.read_csv(f'{DATA_DIR}/label_num_to_disease_map.json')\n",
    "\n",
    "test_images_torch_2019 = CassavaDataset(image_ids=sample_submission.image_id.values, labels=sample_submission.label.values, root=f'{DATA_DIR}/test_images')\n",
    "\n",
    "submission = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "\n",
    "cv_results = {\n",
    "    'fold_0': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_0.pt')\n",
    "    },\n",
    "    'fold_1': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_1.pt')\n",
    "    },\n",
    "    'fold_2': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_2.pt')\n",
    "    },\n",
    "    'fold_3': {\n",
    "        'model_path': os.path.join(MODELS_DIR, 'model_fold_3.pt')\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predict_submission(cv_results, test_images_torch_2020, sample_submission, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cassava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
